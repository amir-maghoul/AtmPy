{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T11:33:40.488643Z",
     "start_time": "2025-04-14T11:33:40.484132Z"
    }
   },
   "cell_type": "code",
   "source": "import numpy as np",
   "id": "9f35ff1f8999d0f0",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T11:33:40.535111Z",
     "start_time": "2025-04-14T11:33:40.527244Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ndim = 2\n",
    "rhs = np.arange(30).reshape((6, 5))\n",
    "igs = [2, 2]\n",
    "factor = 100\n",
    "wall_idx = np.empty((ndim), dtype=object)\n",
    "for dim in range(ndim):\n",
    "    wall_idx[dim] = slice(igs[dim], -igs[dim])\n",
    "print(rhs)\n",
    "for dim in range(ndim):\n",
    "    if True:\n",
    "        for direction in [-1, 1]:\n",
    "            wall_idx[dim] = (igs[dim] - 1) * direction\n",
    "            if direction == -1:\n",
    "                wall_idx[dim] -= 1\n",
    "            wall_idx_tuple = tuple(wall_idx)\n",
    "            rhs[wall_idx_tuple] *= factor\n",
    "            print(wall_idx_tuple)\n",
    "\n",
    "print(rhs)"
   ],
   "id": "b2e1fef74841a7b4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2  3  4]\n",
      " [ 5  6  7  8  9]\n",
      " [10 11 12 13 14]\n",
      " [15 16 17 18 19]\n",
      " [20 21 22 23 24]\n",
      " [25 26 27 28 29]]\n",
      "(-2, slice(2, -2, None))\n",
      "(1, slice(2, -2, None))\n",
      "(1, -2)\n",
      "(1, 1)\n",
      "[[   0    1    2    3    4]\n",
      " [   5  600  700  800    9]\n",
      " [  10   11   12   13   14]\n",
      " [  15   16   17   18   19]\n",
      " [  20   21 2200   23   24]\n",
      " [  25   26   27   28   29]]\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T11:33:40.585968Z",
     "start_time": "2025-04-14T11:33:40.582020Z"
    }
   },
   "cell_type": "code",
   "source": "import numba as nb",
   "id": "5202f45ffb4bbc44",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T11:33:40.670218Z",
     "start_time": "2025-04-14T11:33:40.649989Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def stencil_9pt(elem,node,mpv,Sol,ud,diag_inv,dt,coriolis_params):\n",
    "    igx = elem.igx\n",
    "    igy = elem.igy\n",
    "\n",
    "    icxn = node.icx\n",
    "    icyn = node.icy\n",
    "\n",
    "    iicxn = icxn - (2 * igx)\n",
    "    iicyn = icyn - (2 * igy)\n",
    "\n",
    "    iicxn, iicyn = iicyn, iicxn\n",
    "\n",
    "    dx = node.dy\n",
    "    dy = node.dx\n",
    "\n",
    "    inner_domain = (slice(igx,-igx),slice(igy,-igy))\n",
    "    i1 = node.i1\n",
    "\n",
    "    hplusx = mpv.wplus[1][i1].reshape(-1,)\n",
    "    hplusy = mpv.wplus[0][i1].reshape(-1,)\n",
    "    hcenter = mpv.wcenter[i1].reshape(-1,)\n",
    "\n",
    "    diag_inv = diag_inv[i1].reshape(-1,)\n",
    "\n",
    "    oodx = 1.0 / (dx)\n",
    "    oody = 1.0 / (dy)\n",
    "\n",
    "    x_periodic = ud.bdry_type[1] == opts.BdryType.PERIODIC\n",
    "    y_periodic = ud.bdry_type[0] == opts.BdryType.PERIODIC\n",
    "\n",
    "    x_wall = ud.bdry_type[1] == opts.BdryType.WALL or ud.bdry_type[1] == opts.BdryType.RAYLEIGH\n",
    "    y_wall = ud.bdry_type[0] == opts.BdryType.WALL or ud.bdry_type[0] == opts.BdryType.RAYLEIGH\n",
    "    return lambda p : lap2D_gather(p, igx,igy, iicxn, iicyn, hplusx, hplusy, hcenter, oodx, oody, x_periodic, y_periodic, x_wall, y_wall, diag_inv, coriolis_params)\n",
    "\n",
    "@nb.jit(nopython=True, nogil=False, cache=True)\n",
    "def lap2D_gather(p, igx,igy, iicxn, iicyn, hplusx, hplusy, hcenter, oodx, oody, x_periodic, y_periodic, x_wall, y_wall, diag_inv, coriolis):\n",
    "    ngnc = (iicxn) * (iicyn)\n",
    "    lap = np.zeros((ngnc))\n",
    "    cnt_x = 0\n",
    "    cnt_y = 0\n",
    "\n",
    "    nine_pt = 0.25 * (2.0) * 1.0\n",
    "    cyy, cxx, cyx, cxy = coriolis\n",
    "    oodx2 = 0.5 * oodx**2\n",
    "    oody2 = 0.5 * oody**2\n",
    "\n",
    "    for idx in range(iicxn * iicyn):\n",
    "        ne_topleft = idx - iicxn - 1\n",
    "        ne_topright = idx - iicxn\n",
    "        ne_botleft = idx - 1\n",
    "        ne_botright = idx\n",
    "\n",
    "        # get indices of the 9pt stencil\n",
    "        topleft_idx = idx - iicxn - 1\n",
    "        midleft_idx = idx - 1\n",
    "        botleft_idx = idx + iicxn - 1\n",
    "\n",
    "        topmid_idx = idx - iicxn\n",
    "        midmid_idx = idx\n",
    "        botmid_idx = idx + iicxn\n",
    "\n",
    "        topright_idx = idx - iicxn + 1\n",
    "        midright_idx = idx + 1\n",
    "        botright_idx = idx + iicxn + 1\n",
    "\n",
    "        if cnt_x == 0:\n",
    "            topleft_idx += iicxn - 1\n",
    "            midleft_idx += iicxn - 1\n",
    "            botleft_idx += iicxn - 1\n",
    "\n",
    "            ne_topleft += iicxn - 1\n",
    "            ne_botleft += iicxn - 1\n",
    "\n",
    "        if cnt_x == (iicxn - 1):\n",
    "            topright_idx -= iicxn - 1\n",
    "            midright_idx -= iicxn - 1\n",
    "            botright_idx -= iicxn - 1\n",
    "\n",
    "            ne_topright -= iicxn - 1\n",
    "            ne_botright -= iicxn - 1\n",
    "\n",
    "        if cnt_y == 0:\n",
    "            topleft_idx += ((iicxn) * (iicyn - 1))\n",
    "            topmid_idx += ((iicxn) * (iicyn - 1))\n",
    "            topright_idx += ((iicxn) * (iicyn - 1))\n",
    "\n",
    "            ne_topleft += ((iicxn) * (iicyn - 1))\n",
    "            ne_topright += ((iicxn) * (iicyn - 1))\n",
    "\n",
    "        if cnt_y == (iicyn - 1):\n",
    "            botleft_idx -= ((iicxn) * (iicyn - 1))\n",
    "            botmid_idx -= ((iicxn) * (iicyn - 1))\n",
    "            botright_idx -= ((iicxn) * (iicyn - 1))\n",
    "\n",
    "            ne_botleft -= ((iicxn) * (iicyn - 1))\n",
    "            ne_botright -= ((iicxn) * (iicyn - 1))\n",
    "\n",
    "        topleft = p[topleft_idx]\n",
    "        midleft = p[midleft_idx]\n",
    "        botleft = p[botleft_idx]\n",
    "\n",
    "        topmid = p[topmid_idx]\n",
    "        midmid = p[midmid_idx]\n",
    "        botmid = p[botmid_idx]\n",
    "\n",
    "        topright = p[topright_idx]\n",
    "        midright = p[midright_idx]\n",
    "        botright = p[botright_idx]\n",
    "\n",
    "        hplusx_topleft = hplusx[ne_topleft]\n",
    "        hplusx_botleft = hplusx[ne_botleft]\n",
    "        hplusy_topleft = hplusy[ne_topleft]\n",
    "        hplusy_botleft = hplusy[ne_botleft]\n",
    "\n",
    "        hplusx_topright = hplusx[ne_topright]\n",
    "        hplusx_botright = hplusx[ne_botright]\n",
    "        hplusy_topright = hplusy[ne_topright]\n",
    "        hplusy_botright = hplusy[ne_botright]\n",
    "\n",
    "        cxx_tl  = cxx[ne_topleft]\n",
    "        cxx_tr = cxx[ne_topright]\n",
    "        cxx_bl  = cxx[ne_botleft]\n",
    "        cxx_br = cxx[ne_botright]\n",
    "\n",
    "        cxy_tl  = cxy[ne_topleft]\n",
    "        cxy_tr  = cxy[ne_topright]\n",
    "        cxy_bl  = cxy[ne_botleft]\n",
    "        cxy_br  = cxy[ne_botright]\n",
    "\n",
    "        cyx_tl  = cyx[ne_topleft]\n",
    "        cyx_tr  = cyx[ne_topright]\n",
    "        cyx_bl  = cyx[ne_botleft]\n",
    "        cyx_br  = cyx[ne_botright]\n",
    "\n",
    "        cyy_tl  = cyy[ne_topleft]\n",
    "        cyy_tr  = cyy[ne_topright]\n",
    "        cyy_bl  = cyy[ne_botleft]\n",
    "        cyy_br  = cyy[ne_botright]\n",
    "\n",
    "        Dx_tl = 0.5 * (topmid   - topleft + midmid   - midleft) * hplusx_topleft\n",
    "        Dx_tr = 0.5 * (topright - topmid  + midright - midmid ) * hplusx_topright\n",
    "        Dx_bl = 0.5 * (botmid   - botleft + midmid   - midleft) * hplusx_botleft\n",
    "        Dx_br = 0.5 * (botright - botmid  + midright - midmid ) * hplusx_botright\n",
    "\n",
    "        Dy_tl = 0.5 * (midmid   - topmid   + midleft - topleft) * hplusy_topleft\n",
    "        Dy_tr = 0.5 * (midright - topright + midmid  - topmid ) * hplusy_topright\n",
    "        Dy_bl = 0.5 * (botmid   - midmid   + botleft - midleft) * hplusy_botleft\n",
    "        Dy_br = 0.5 * (botright - midright + botmid  - midmid ) * hplusy_botright\n",
    "\n",
    "        fac = 1.0\n",
    "        Dxx = 0.5 * (cxx_tr * Dx_tr - cxx_tl * Dx_tl + cxx_br * Dx_br - cxx_bl * Dx_bl) * oodx * oodx * fac\n",
    "        Dyy = 0.5 * (cyy_br * Dy_br - cyy_tr * Dy_tr + cyy_bl * Dy_bl - cyy_tl * Dy_tl) * oody * oody * fac\n",
    "        Dyx = 0.5 * (cyx_br * Dy_br - cyx_bl * Dy_bl + cyx_tr * Dy_tr - cyx_tl * Dy_tl) * oody * oodx * fac\n",
    "        Dxy = 0.5 * (cxy_br * Dx_br - cxy_tr * Dx_tr + cxy_bl * Dy_bl - cxy_tl * Dx_tl) * oodx * oody * fac\n",
    "\n",
    "\n",
    "        lap[idx] = Dxx + Dyy + Dyx + Dxy + hcenter[idx] * p[idx]\n"
   ],
   "id": "a91aa8eac63605a7",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T11:33:40.730522Z",
     "start_time": "2025-04-14T11:33:40.707145Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import numba as nb\n",
    "\n",
    "# Define constants for clarity\n",
    "HALF = 0.5\n",
    "\n",
    "@nb.jit(nopython=True, nogil=True, cache=True, fastmath=False) # nogil=True should be safe\n",
    "def lap2D_gather_fused(\n",
    "    p_node: np.ndarray,      # Input pressure vector (flattened internal nodes)\n",
    "    iicxn: int,              # Number of internal nodes in x\n",
    "    iicyn: int,              # Number of internal nodes in y\n",
    "    hplusx_elem: np.ndarray, # Coefficient array (ELEMENT-centered or face-centered)\n",
    "    hplusy_elem: np.ndarray, # Coefficient array (ELEMENT-centered or face-centered)\n",
    "    hcenter_node: np.ndarray,# Coefficient array (NODE-centered)\n",
    "    oodx: float,             # 1 / dx\n",
    "    oody: float,             # 1 / dy\n",
    "    x_periodic: bool,        # Boolean or int flag\n",
    "    y_periodic: bool,        # Boolean or int flag\n",
    "    x_wall: bool,            # Boolean or int flag\n",
    "    y_wall: bool,            # Boolean or int flag\n",
    "    diag_inv_node: np.ndarray,# Diagonal preconditioner (NODE-centered)\n",
    "    coriolis_elem: tuple,    # Tuple of ELEMENT-centered coeff arrays (cyy, cxx, cyx, cxy)\n",
    "    out: np.ndarray = None   # Optional output array for in-place operation\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calculates the action of a 2D discretized operator (Laplacian + Coriolis)\n",
    "    on a vector 'p_node' using a 9-point stencil (matrix-free via Numba).\n",
    "\n",
    "    Handles periodic and wall boundary conditions by adjusting coefficients.\n",
    "    Operates on flattened arrays corresponding to internal grid nodes/elements.\n",
    "\n",
    "    Args:\n",
    "        p_node: Flattened 1D array of input values at internal nodes.\n",
    "        iicxn, iicyn: Internal grid dimensions (number of nodes).\n",
    "        hplusx_elem, hplusy_elem: Coefficient arrays, assumed mapped to elements\n",
    "                                 (e.g., indexed by bottom-left node's internal index).\n",
    "                                 Size should match number of internal elements.\n",
    "        hcenter_node: Central coefficient at each internal node. Size ngnc.\n",
    "        oodx, oody: Grid spacing reciprocals.\n",
    "        x_periodic, y_periodic: Flags for periodic boundaries.\n",
    "        x_wall, y_wall: Flags for wall boundaries (assumed zero Neumann).\n",
    "        diag_inv_node: Diagonal preconditioning values at each internal node. Size ngnc.\n",
    "        coriolis_elem: Tuple (cyy, cxx, cyx, cxy) of coefficient arrays,\n",
    "                       assumed mapped to elements.\n",
    "        out: Optional pre-allocated array (size ngnc) to store the result.\n",
    "\n",
    "    Returns:\n",
    "        A 1D numpy array (size ngnc) containing the result of the operator\n",
    "        applied to p_node. If 'out' was provided, it returns 'out'.\n",
    "    \"\"\"\n",
    "    ngnc = iicxn * iicyn # Total number of internal nodes\n",
    "\n",
    "    # Initialize output array\n",
    "    if out is None:\n",
    "        lap_node = np.zeros(ngnc, dtype=p_node.dtype)\n",
    "    else:\n",
    "        # Ensure the output array has the correct shape if provided\n",
    "        if out.shape[0] != ngnc:\n",
    "            # Numba doesn't support raising exceptions easily, maybe return zeros or handle outside\n",
    "            return np.zeros(ngnc, dtype=p_node.dtype) # Indicate error state\n",
    "        lap_node = out\n",
    "        lap_node[:] = 0.0 # Zero out array if accumulating isn't desired\n",
    "\n",
    "    # Unpack Coriolis terms for clarity\n",
    "    cyy_elem, cxx_elem, cyx_elem, cxy_elem = coriolis_elem\n",
    "\n",
    "    # Use nested loops for better 2D clarity\n",
    "    for j in range(iicyn):  # Loop over y index (internal nodes, 0 to iicyn-1)\n",
    "        for i in range(iicxn):  # Loop over x index (internal nodes, 0 to iicxn-1)\n",
    "            # --- Calculate current node index ---\n",
    "            idx_mid = j * iicxn + i\n",
    "\n",
    "            # --- Determine neighbor node coordinates (ni, nj) with periodic wrapping ---\n",
    "            # Note: Python's % handles negative numbers correctly for wrapping in Numba too\n",
    "            i_w = (i - 1 + iicxn) % iicxn if x_periodic else i - 1\n",
    "            i_e = (i + 1) % iicxn         if x_periodic else i + 1\n",
    "            j_s = (j - 1 + iicyn) % iicyn if y_periodic else j - 1\n",
    "            j_n = (j + 1) % iicyn         if y_periodic else j + 1\n",
    "\n",
    "            # --- Calculate flattened neighbor indices in 'p_node' array ---\n",
    "            # These indices are potentially invalid if walls are present,\n",
    "            # but we fetch p values first and apply BCs via coefficients later.\n",
    "            idx_mm = idx_mid           # Middle-Middle (center)\n",
    "            idx_wm = j * iicxn + i_w   # West-Middle\n",
    "            idx_em = j * iicxn + i_e   # East-Middle\n",
    "            idx_ms = j_s * iicxn + i   # Middle-South\n",
    "            idx_mn = j_n * iicxn + i   # Middle-North\n",
    "            idx_ws = j_s * iicxn + i_w # West-South\n",
    "            idx_es = j_s * iicxn + i_e # East-South\n",
    "            idx_wn = j_n * iicxn + i_w # West-North\n",
    "            idx_en = j_n * iicxn + i_e # East-North\n",
    "\n",
    "            # --- Boundary Checks for Non-Periodic Walls ---\n",
    "            # These flags determine if a neighbor is *logically* outside a wall\n",
    "            on_west_boundary  = (not x_periodic and i == 0)\n",
    "            on_east_boundary  = (not x_periodic and i == iicxn - 1)\n",
    "            on_south_boundary = (not y_periodic and j == 0)\n",
    "            on_north_boundary = (not y_periodic and j == iicyn - 1)\n",
    "\n",
    "            # --- Gather 'p' values from neighbors ---\n",
    "            # For wall boundaries, fetch the value from the boundary node itself (p[idx_mid])\n",
    "            # This effectively applies the Neumann BC when combined with zeroed coefficients later.\n",
    "            p_mm = p_node[idx_mm]\n",
    "            p_wm = p_node[idx_wm if not on_west_boundary else idx_mm]\n",
    "            p_em = p_node[idx_em if not on_east_boundary else idx_mm]\n",
    "            p_ms = p_node[idx_ms if not on_south_boundary else idx_mm]\n",
    "            p_mn = p_node[idx_mn if not on_north_boundary else idx_mm]\n",
    "\n",
    "            p_ws = p_node[idx_ws if not (on_west_boundary or on_south_boundary) else idx_mm]\n",
    "            p_es = p_node[idx_es if not (on_east_boundary or on_south_boundary) else idx_mm]\n",
    "            p_wn = p_node[idx_wn if not (on_west_boundary or on_north_boundary) else idx_mm]\n",
    "            p_en = p_node[idx_en if not (on_east_boundary or on_north_boundary) else idx_mm]\n",
    "\n",
    "\n",
    "            # --- Determine element indices for coefficients ---\n",
    "            # Assuming coeffs arrays (hplus, coriolis) are mapped based on the\n",
    "            # bottom-left node's *internal* index.\n",
    "            # Calculate the potential indices of the 4 surrounding elements' bottom-left nodes.\n",
    "            # Need to handle periodicity/walls for these indices if coeff arrays only store internal elements.\n",
    "            elem_idx_sw = ((j - 1 + iicyn) % iicyn if y_periodic else j - 1) * iicxn + \\\n",
    "                          ((i - 1 + iicxn) % iicxn if x_periodic else i - 1)\n",
    "            elem_idx_se = ((j - 1 + iicyn) % iicyn if y_periodic else j - 1) * iicxn + \\\n",
    "                          (i % iicxn if x_periodic else i) # Use i directly for SE/NE x-index\n",
    "            elem_idx_nw = (j % iicyn if y_periodic else j) * iicxn + \\\n",
    "                          ((i - 1 + iicxn) % iicxn if x_periodic else i - 1)\n",
    "            elem_idx_ne = (j % iicyn if y_periodic else j) * iicxn + \\\n",
    "                          (i % iicxn if x_periodic else i) # Current node (j,i) is bottom-left of NE element\n",
    "\n",
    "            # --- Gather Coefficients (hplus, coriolis) ---\n",
    "            # Use helper function to safely get coefficients, handling potential\n",
    "            # out-of-bounds access for wall boundaries by returning 0.0\n",
    "\n",
    "            # SW Element Coefficients\n",
    "            valid_sw = (not (on_west_boundary or on_south_boundary))\n",
    "            hpx_sw = hplusx_elem[elem_idx_sw] if valid_sw else 0.0\n",
    "            hpy_sw = hplusy_elem[elem_idx_sw] if valid_sw else 0.0\n",
    "            cxx_sw = cxx_elem[elem_idx_sw] if valid_sw else 0.0\n",
    "            cyy_sw = cyy_elem[elem_idx_sw] if valid_sw else 0.0\n",
    "            cxy_sw = cxy_elem[elem_idx_sw] if valid_sw else 0.0\n",
    "            cyx_sw = cyx_elem[elem_idx_sw] if valid_sw else 0.0\n",
    "\n",
    "            # SE Element Coefficients\n",
    "            valid_se = (not (on_east_boundary or on_south_boundary))\n",
    "            hpx_se = hplusx_elem[elem_idx_se] if valid_se else 0.0\n",
    "            hpy_se = hplusy_elem[elem_idx_se] if valid_se else 0.0\n",
    "            cxx_se = cxx_elem[elem_idx_se] if valid_se else 0.0\n",
    "            cyy_se = cyy_elem[elem_idx_se] if valid_se else 0.0\n",
    "            cxy_se = cxy_elem[elem_idx_se] if valid_se else 0.0\n",
    "            cyx_se = cyx_elem[elem_idx_se] if valid_se else 0.0\n",
    "\n",
    "            # NW Element Coefficients\n",
    "            valid_nw = (not (on_west_boundary or on_north_boundary))\n",
    "            hpx_nw = hplusx_elem[elem_idx_nw] if valid_nw else 0.0\n",
    "            hpy_nw = hplusy_elem[elem_idx_nw] if valid_nw else 0.0\n",
    "            cxx_nw = cxx_elem[elem_idx_nw] if valid_nw else 0.0\n",
    "            cyy_nw = cyy_elem[elem_idx_nw] if valid_nw else 0.0\n",
    "            cxy_nw = cxy_elem[elem_idx_nw] if valid_nw else 0.0\n",
    "            cyx_nw = cyx_elem[elem_idx_nw] if valid_nw else 0.0\n",
    "\n",
    "            # NE Element Coefficients\n",
    "            valid_ne = (not (on_east_boundary or on_north_boundary))\n",
    "            hpx_ne = hplusx_elem[elem_idx_ne] if valid_ne else 0.0\n",
    "            hpy_ne = hplusy_elem[elem_idx_ne] if valid_ne else 0.0\n",
    "            cxx_ne = cxx_elem[elem_idx_ne] if valid_ne else 0.0\n",
    "            cyy_ne = cyy_elem[elem_idx_ne] if valid_ne else 0.0\n",
    "            cxy_ne = cxy_elem[elem_idx_ne] if valid_ne else 0.0\n",
    "            cyx_ne = cyx_elem[elem_idx_ne] if valid_ne else 0.0\n",
    "\n",
    "            # --- Calculate fluxes / derivatives (using gathered p and coeffs) ---\n",
    "            # These coefficients (hpx_*, cxx_*, etc.) are now correctly zeroed\n",
    "            # if they correspond to an element outside a wall boundary.\n",
    "            Dx_tl = HALF * (p_mn - p_wn + p_mm - p_wm) * hpx_nw # Top-Left face flux approx\n",
    "            Dx_tr = HALF * (p_en - p_mn + p_em - p_mm) * hpx_ne # Top-Right face flux approx\n",
    "            Dx_bl = HALF * (p_mm - p_wm + p_ms - p_ws) * hpx_sw # Bottom-Left face flux approx\n",
    "            Dx_br = HALF * (p_em - p_mm + p_es - p_ms) * hpx_se # Bottom-Right face flux approx\n",
    "\n",
    "            Dy_tl = HALF * (p_mm - p_mn + p_wm - p_wn) * hpy_nw # Top-Left face flux approx\n",
    "            Dy_tr = HALF * (p_em - p_en + p_mm - p_mn) * hpy_ne # Top-Right face flux approx\n",
    "            Dy_bl = HALF * (p_ms - p_mm + p_ws - p_wm) * hpy_sw # Bottom-Left face flux approx\n",
    "            Dy_br = HALF * (p_es - p_em + p_ms - p_mm) * hpy_se # Bottom-Right face flux approx\n",
    "\n",
    "            # --- Combine terms for the operator action at 'idx_mid' ---\n",
    "            # Based on divergence form: d/dx(F_x) + d/dy(F_y)\n",
    "            # F_x approx = cxx * Dx + cxy * Dy\n",
    "            # F_y approx = cyx * Dx + cyy * Dy\n",
    "            # d/dx(F_x) approx = ( F_x_east_face - F_x_west_face ) * oodx\n",
    "            # d/dy(F_y) approx = ( F_y_north_face - F_y_south_face ) * oody\n",
    "\n",
    "            # Approximate fluxes at cell faces around node (i,j)\n",
    "            Fx_west = HALF * (cxx_sw * Dx_bl + cxx_nw * Dx_tl + cxy_sw * Dy_bl + cxy_nw * Dy_tl)\n",
    "            Fx_east = HALF * (cxx_se * Dx_br + cxx_ne * Dx_tr + cxy_se * Dy_br + cxy_ne * Dy_tr)\n",
    "            Fy_south = HALF * (cyx_sw * Dx_bl + cyx_se * Dx_br + cyy_sw * Dy_bl + cyy_se * Dy_br)\n",
    "            Fy_north = HALF * (cyx_nw * Dx_tl + cyx_ne * Dx_tr + cyy_nw * Dy_tl + cyy_ne * Dy_tr)\n",
    "\n",
    "            divergence = (Fx_east - Fx_west) * oodx + (Fy_north - Fy_south) * oody\n",
    "\n",
    "            # --- Final value for the node ---\n",
    "            # Check if the original formula includes the hcenter term *before* or *after* divergence.\n",
    "            # Assuming it's added:\n",
    "            lap_val = divergence + hcenter_node[idx_mid] * p_mm\n",
    "\n",
    "            # Apply diagonal preconditioner\n",
    "            lap_node[idx_mid] = lap_val * diag_inv_node[idx_mid]\n",
    "\n",
    "    return lap_node"
   ],
   "id": "11f5038a1e263ca9",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-14T11:33:42.001729Z",
     "start_time": "2025-04-14T11:33:40.770166Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "#\n",
    "# # --- Assume functions are defined/imported ---\n",
    "# # Make sure these placeholder functions have the EXACT same signature\n",
    "# # as your actual functions. Replace the imports/definitions below.\n",
    "#\n",
    "# # Placeholder for the ORIGINAL Numba function\n",
    "# try:\n",
    "#     # Option 1: If it's in a file named, e.g., original_laplacian.py\n",
    "#     from original_laplacian import lap2D_gather as lap2D_gather_original\n",
    "#     print(\"Imported lap2D_gather_original from original_laplacian.py\")\n",
    "# except ImportError:\n",
    "#     print(\"Warning: Could not import lap2D_gather_original. Using placeholder.\")\n",
    "#     # Option 2: Define a dummy placeholder if the real one isn't available\n",
    "#     # This will likely fail comparisons but allows the script structure to run.\n",
    "#     import numba as nb\n",
    "#     @nb.jit(nopython=True)\n",
    "#     def lap2D_gather_original(p, igx,igy, iicxn, iicyn, hplusx, hplusy, hcenter, oodx, oody, x_periodic, y_periodic, x_wall, y_wall, diag_inv, coriolis):\n",
    "#         # This placeholder just returns zeros - REPLACE IT with your original code\n",
    "#         # Note: The signature must match EXACTLY, including parameter names if\n",
    "#         # the original code relied on them implicitly (though less likely in Numba).\n",
    "#         # The dummy 'igx', 'igy' are included here assuming they were in the original\n",
    "#         # even if unused, to maintain the signature for the call.\n",
    "#         ngnc = iicxn * iicyn\n",
    "#         return np.zeros(ngnc, dtype=p.dtype)\n",
    "#\n",
    "# # Placeholder for the NEW Refactored Numba function\n",
    "# try:\n",
    "#     # Option 1: If it's in a file named, e.g., refactored_laplacian.py\n",
    "#     from refactored_laplacian import lap2D_gather_refactored_numba\n",
    "#     print(\"Imported lap2D_gather_refactored_numba from refactored_laplacian.py\")\n",
    "# except ImportError:\n",
    "#     print(\"Warning: Could not import lap2D_gather_refactored_numba. Using placeholder.\")\n",
    "#     # Option 2: Define a dummy placeholder\n",
    "#     import numba as nb\n",
    "#     @nb.jit(nopython=True)\n",
    "#     def lap2D_gather_refactored_numba(p_node: np.ndarray, iicxn: int, iicyn: int, hplusx_elem: np.ndarray, hplusy_elem: np.ndarray, hcenter_node: np.ndarray, oodx: float, oody: float, x_periodic: bool, y_periodic: bool, x_wall: bool, y_wall: bool, diag_inv_node: np.ndarray, coriolis_elem: tuple, out: np.ndarray = None):\n",
    "#         # This placeholder just returns zeros - REPLACE IT with your refactored code\n",
    "#         ngnc = iicxn * iicyn\n",
    "#         if out is None:\n",
    "#             out = np.zeros(ngnc, dtype=p_node.dtype)\n",
    "#         else:\n",
    "#             out[:] = 0.0\n",
    "#         return out\n",
    "# # --- End Placeholder functions ---\n",
    "\n",
    "\n",
    "def run_numba_comparison(iicxn, iicyn, num_trials=10):\n",
    "    \"\"\"\n",
    "    Compares the original and refactored Numba implementations.\n",
    "    \"\"\"\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"Running comparison for grid size: {iicxn} x {iicyn}\")\n",
    "    print(f\"Number of trials for timing: {num_trials}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    ngnc = iicxn * iicyn # Number of internal grid nodes\n",
    "    nelem = iicxn * iicyn # Assuming element count matches internal nodes\n",
    "    # Dummy ghost cell info if needed by original signature (adjust if different)\n",
    "    igx, igy = 2, 2\n",
    "\n",
    "    # --- Generate Consistent Random Test Data (CPU) ---\n",
    "    np.random.seed(42)\n",
    "    p_np = np.random.rand(ngnc).astype(np.float64)\n",
    "    hplusx_np = np.random.rand(nelem).astype(np.float64) + 0.1\n",
    "    hplusy_np = np.random.rand(nelem).astype(np.float64) + 0.1\n",
    "    hcenter_np = np.random.rand(ngnc).astype(np.float64) * 5.0 + 1.0\n",
    "    diag_inv_np = (1.0 / hcenter_np).astype(np.float64)\n",
    "    coriolis_np = tuple([ (np.random.rand(nelem).astype(np.float64) - 0.5) * 0.1 for _ in range(4) ])\n",
    "\n",
    "    oodx = float(iicxn)\n",
    "    oody = float(iicyn)\n",
    "    x_periodic, y_periodic = True, True\n",
    "    x_wall, y_wall = False, False\n",
    "\n",
    "    # --- 1. Run Original Numba Version ---\n",
    "    print(\"Running Original Numba version...\")\n",
    "    try:\n",
    "        # Warm-up call\n",
    "        _ = lap2D_gather(p_np, igx, igy, iicxn, iicyn, hplusx_np, hplusy_np, hcenter_np, oodx, oody,\n",
    "                         x_periodic, y_periodic, x_wall, y_wall, diag_inv_np, coriolis_np)\n",
    "\n",
    "        start_time_orig = time.perf_counter()\n",
    "        for _ in range(num_trials):\n",
    "            result_orig = lap2D_gather(p_np, igx, igy, iicxn, iicyn, hplusx_np, hplusy_np, hcenter_np, oodx, oody,\n",
    "                                     x_periodic, y_periodic, x_wall, y_wall, diag_inv_np, coriolis_np)\n",
    "        end_time_orig = time.perf_counter()\n",
    "        time_orig_avg = (end_time_orig - start_time_orig) / num_trials\n",
    "        print(f\"Original average execution time: {time_orig_avg:.6f} seconds\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error running original version: {e}\")\n",
    "        time_orig_avg = float('inf')\n",
    "        result_orig = None\n",
    "\n",
    "\n",
    "    # --- 2. Run Refactored Numba Version ---\n",
    "    print(\"\\nRunning Refactored Numba version...\")\n",
    "    try:\n",
    "        # Optional output buffer for refactored version\n",
    "        out_buffer = np.zeros_like(p_np)\n",
    "        # Warm-up call\n",
    "        _ = lap2D_gather_refactored_numba(p_np, iicxn, iicyn, hplusx_np, hplusy_np, hcenter_np, oodx, oody,\n",
    "                                x_periodic, y_periodic, x_wall, y_wall, diag_inv_np, coriolis_np, out=out_buffer)\n",
    "\n",
    "        start_time_ref = time.perf_counter()\n",
    "        for _ in range(num_trials):\n",
    "            # Example using the output buffer\n",
    "            result_ref = lap2D_gather_refactored_numba(p_np, iicxn, iicyn, hplusx_np, hplusy_np, hcenter_np, oodx, oody,\n",
    "                                           x_periodic, y_periodic, x_wall, y_wall, diag_inv_np, coriolis_np, out=out_buffer)\n",
    "            # Or call without 'out' if preferred:\n",
    "            # result_ref = lap2D_gather_refactored_numba(p_np, iicxn, iicyn, hplusx_np, hplusy_np, hcenter_np, oodx, oody,\n",
    "            #                                x_periodic, y_periodic, x_wall, y_wall, diag_inv_np, coriolis_np)\n",
    "        end_time_ref = time.perf_counter()\n",
    "        time_ref_avg = (end_time_ref - start_time_ref) / num_trials\n",
    "        print(f\"Refactored average execution time: {time_ref_avg:.6f} seconds\")\n",
    "        # If using 'out', result_ref is the same buffer 'out_buffer'\n",
    "        if 'out_buffer' in locals() and result_ref is out_buffer:\n",
    "             result_ref = out_buffer.copy() # Copy if needed for comparison, as buffer is overwritten\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error running refactored version: {e}\")\n",
    "        time_ref_avg = float('inf')\n",
    "        result_ref = None\n",
    "\n",
    "    # --- 3. Compare Results ---\n",
    "    print(\"\\nComparing results...\")\n",
    "    if result_orig is not None and result_ref is not None:\n",
    "        try:\n",
    "            are_close = np.allclose(result_orig, result_ref, rtol=1e-9, atol=1e-12) # Use tighter tolerance\n",
    "            print(f\"Results are close: {are_close}\")\n",
    "            if not are_close:\n",
    "                diff = np.abs(result_orig - result_ref)\n",
    "                max_abs_diff = np.max(diff)\n",
    "                # Calculate relative difference carefully\n",
    "                # Add small epsilon to denominator to avoid division by zero/large rel diff for small numbers\n",
    "                denom = np.maximum(np.abs(result_orig), np.abs(result_ref)) + 1e-15\n",
    "                max_rel_diff = np.max(diff / denom)\n",
    "\n",
    "                print(f\"  Max absolute difference: {max_abs_diff:.2e}\")\n",
    "                print(f\"  Max relative difference: {max_rel_diff:.2e}\")\n",
    "                # Optionally print indices where differences occur\n",
    "                # diff_indices = np.where(~np.isclose(result_orig, result_ref, rtol=1e-9, atol=1e-12))[0]\n",
    "                # print(f\"  Indices with differences (first few): {diff_indices[:10]}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error during comparison: {e}\")\n",
    "            print(f\"  Original result shape: {result_orig.shape}, dtype: {result_orig.dtype}\")\n",
    "            print(f\"  Refactored result shape: {result_ref.shape}, dtype: {result_ref.dtype}\")\n",
    "    else:\n",
    "        print(\"Comparison skipped due to missing results.\")\n",
    "\n",
    "    print(\"-\" * 60)\n",
    "    return time_orig_avg, time_ref_avg\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # --- Configuration ---\n",
    "    grid_sizes = [(32, 32), (64, 64), (128, 128), (256, 256)] # Test different sizes\n",
    "    trials = 100 # Number of repetitions for timing\n",
    "\n",
    "    # --- Run Comparisons ---\n",
    "    results = {}\n",
    "    for size in grid_sizes:\n",
    "        iicxn, iicyn = size\n",
    "        try:\n",
    "            orig_t, ref_t = run_numba_comparison(iicxn, iicyn, num_trials=trials)\n",
    "            results[size] = {'original_time': orig_t, 'refactored_time': ref_t}\n",
    "        except Exception as e:\n",
    "            print(f\"\\n!!!!!! Error during comparison for size {size}: {e} !!!!!!\\n\")\n",
    "            results[size] = {'original_time': float('inf'), 'refactored_time': float('inf')}\n",
    "\n",
    "\n",
    "    # --- Print Summary ---\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Numba Comparison Summary (Average Times in seconds)\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"{'Grid Size':<12} | {'Original Time':<18} | {'Refactored Time':<18} | {'Speedup (Ref/Orig)':<18}\")\n",
    "    print(\"-\" * 60)\n",
    "    for size, times in results.items():\n",
    "        orig_t = times['original_time']\n",
    "        ref_t = times['refactored_time']\n",
    "        if orig_t == 0 or orig_t == float('inf') or ref_t == float('inf'):\n",
    "            speedup_str = \"N/A\"\n",
    "        else:\n",
    "            speedup = orig_t / ref_t\n",
    "            speedup_str = f\"{speedup:.2f}x\"\n",
    "        print(f\"{f'{size[0]}x{size[1]}':<12} | {orig_t:.6f}{'s':<12} | {ref_t:.6f}{'s':<12} | {speedup_str:<18}\")\n",
    "    print(\"=\" * 60)"
   ],
   "id": "b9c55b007f0931ad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Running comparison for grid size: 32 x 32\n",
      "Number of trials for timing: 100\n",
      "------------------------------------------------------------\n",
      "Running Original Numba version...\n",
      "Original average execution time: 0.000053 seconds\n",
      "\n",
      "Running Refactored Numba version...\n",
      "Error running refactored version: name 'lap2D_gather_refactored_numba' is not defined\n",
      "\n",
      "Comparing results...\n",
      "Comparison skipped due to missing results.\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "Running comparison for grid size: 64 x 64\n",
      "Number of trials for timing: 100\n",
      "------------------------------------------------------------\n",
      "Running Original Numba version...\n",
      "Original average execution time: 0.000208 seconds\n",
      "\n",
      "Running Refactored Numba version...\n",
      "Error running refactored version: name 'lap2D_gather_refactored_numba' is not defined\n",
      "\n",
      "Comparing results...\n",
      "Comparison skipped due to missing results.\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "Running comparison for grid size: 128 x 128\n",
      "Number of trials for timing: 100\n",
      "------------------------------------------------------------\n",
      "Running Original Numba version...\n",
      "Original average execution time: 0.000617 seconds\n",
      "\n",
      "Running Refactored Numba version...\n",
      "Error running refactored version: name 'lap2D_gather_refactored_numba' is not defined\n",
      "\n",
      "Comparing results...\n",
      "Comparison skipped due to missing results.\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "Running comparison for grid size: 256 x 256\n",
      "Number of trials for timing: 100\n",
      "------------------------------------------------------------\n",
      "Running Original Numba version...\n",
      "Original average execution time: 0.001901 seconds\n",
      "\n",
      "Running Refactored Numba version...\n",
      "Error running refactored version: name 'lap2D_gather_refactored_numba' is not defined\n",
      "\n",
      "Comparing results...\n",
      "Comparison skipped due to missing results.\n",
      "------------------------------------------------------------\n",
      "\n",
      "============================================================\n",
      "Numba Comparison Summary (Average Times in seconds)\n",
      "============================================================\n",
      "Grid Size    | Original Time      | Refactored Time    | Speedup (Ref/Orig)\n",
      "------------------------------------------------------------\n",
      "32x32        | 0.000053s            | infs            | N/A               \n",
      "64x64        | 0.000208s            | infs            | N/A               \n",
      "128x128      | 0.000617s            | infs            | N/A               \n",
      "256x256      | 0.001901s            | infs            | N/A               \n",
      "============================================================\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "\n",
    "def gradient_nodal_to_interface(p_nodal: np.ndarray,\n",
    "                                dx: float, dy: float,\n",
    "                                nx: int, ny: int) -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Computes the gradient of a nodal scalar field, evaluating components\n",
    "    at the corresponding interface centers.\n",
    "\n",
    "    Args:\n",
    "        p_nodal (np.ndarray): Scalar field defined on nodes, shape (nx+1, ny+1).\n",
    "                              Assumes boundary values are appropriately set.\n",
    "        dx (float): Grid spacing in x.\n",
    "        dy (float): Grid spacing in y.\n",
    "        nx (int): Number of cells (inner nodes) in x direction.\n",
    "        ny (int): Number of cells (inner nodes) in y direction.\n",
    "\n",
    "    Returns:\n",
    "        tuple[np.ndarray, np.ndarray]:\n",
    "            - grad_x_at_x_interfaces: dP/dx evaluated at vertical (x) interfaces,\n",
    "                                      shape (nx, ny+1). Index (i, j) corresponds\n",
    "                                      to interface between nodes (i,j) and (i+1,j).\n",
    "            - grad_y_at_y_interfaces: dP/dy evaluated at horizontal (y) interfaces,\n",
    "                                      shape (nx+1, ny). Index (i, j) corresponds\n",
    "                                      to interface between nodes (i,j) and (i,j+1).\n",
    "    \"\"\"\n",
    "    if p_nodal.shape != (nx + 1, ny + 1):\n",
    "        raise ValueError(f\"Input p_nodal shape {p_nodal.shape} does not match expected ({nx+1}, {ny+1})\")\n",
    "\n",
    "    # Calculate dP/dx at vertical interfaces (between columns)\n",
    "    # Difference along axis=0 (x-direction)\n",
    "    grad_x_at_x_interfaces = (p_nodal[1:, :] - p_nodal[:-1, :]) / dx\n",
    "\n",
    "    # Calculate dP/dy at horizontal interfaces (between rows)\n",
    "    # Difference along axis=1 (y-direction)\n",
    "    grad_y_at_y_interfaces = (p_nodal[:, 1:] - p_nodal[:, :-1]) / dy\n",
    "\n",
    "    # Check shapes\n",
    "    if grad_x_at_x_interfaces.shape != (nx, ny + 1):\n",
    "         raise RuntimeError(f\"Internal error: grad_x shape {grad_x_at_x_interfaces.shape} unexpected.\")\n",
    "    if grad_y_at_y_interfaces.shape != (nx + 1, ny):\n",
    "         raise RuntimeError(f\"Internal error: grad_y shape {grad_y_at_y_interfaces.shape} unexpected.\")\n",
    "\n",
    "    return grad_x_at_x_interfaces, grad_y_at_y_interfaces"
   ],
   "id": "6fcb56609776048d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "\n",
    "def divergence_interface_to_nodal(flux_x_at_x_interfaces: np.ndarray,\n",
    "                                  flux_y_at_y_interfaces: np.ndarray,\n",
    "                                  dx: float, dy: float,\n",
    "                                  nx: int, ny: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Computes the divergence of a vector field F, given its normal components\n",
    "    defined on the interface centers. The divergence is evaluated at the\n",
    "    inner nodes.\n",
    "\n",
    "    This implements Div(F) = d(Fx)/dx + d(Fy)/dy using centered differences\n",
    "    based on interface fluxes.\n",
    "\n",
    "    Args:\n",
    "        flux_x_at_x_interfaces (np.ndarray): Fx component evaluated at vertical\n",
    "                                            (x) interfaces, shape (nx, ny+1).\n",
    "                                            Index (i, j) is flux between nodes\n",
    "                                            (i,j) and (i+1,j).\n",
    "        flux_y_at_y_interfaces (np.ndarray): Fy component evaluated at horizontal\n",
    "                                            (y) interfaces, shape (nx+1, ny).\n",
    "                                            Index (i, j) is flux between nodes\n",
    "                                            (i,j) and (i,j+1).\n",
    "        dx (float): Grid spacing in x.\n",
    "        dy (float): Grid spacing in y.\n",
    "        nx (int): Number of cells (inner nodes) in x direction.\n",
    "        ny (int): Number of cells (inner nodes) in y direction.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Divergence evaluated at inner nodes, shape (nx, ny).\n",
    "                    Index (i,j) corresponds to inner node originally at\n",
    "                    p_nodal[i+1, j+1].\n",
    "    \"\"\"\n",
    "    if flux_x_at_x_interfaces.shape != (nx, ny + 1):\n",
    "         raise ValueError(f\"Input flux_x shape {flux_x_at_x_interfaces.shape} does not match expected ({nx}, {ny+1})\")\n",
    "    if flux_y_at_y_interfaces.shape != (nx + 1, ny):\n",
    "         raise ValueError(f\"Input flux_y shape {flux_y_at_y_interfaces.shape} does not match expected ({nx+1}, {ny})\")\n",
    "\n",
    "    # Calculate d(Fx)/dx at nodes (i+1, j+1) for i=0..nx-1, j=0..ny-1\n",
    "    # Requires Fx at interfaces (i+1/2, j+1) and (i+1/2, j) -> Fx[i, j+1]\n",
    "    # and Fx at interfaces (i-1/2, j+1) and (i-1/2, j) -> Fx[i-1, j+1]\n",
    "    # The indices need careful thought. Let's target node (I, J) where I=1..nx, J=1..ny\n",
    "    # Node (I, J) is surrounded by x-interfaces at index (I-1, J) and (I, J)\n",
    "    # and y-interfaces at index (I, J-1) and (I, J).\n",
    "\n",
    "    # Difference Fx across the node in x-direction\n",
    "    # flux_x_at_x_interfaces[I, J] is the flux on the right interface of node (I,J)\n",
    "    # flux_x_at_x_interfaces[I-1, J] is the flux on the left interface of node (I,J)\n",
    "    # We need these for J=1..ny (inner nodes plus boundaries in y)\n",
    "    dFx_dx_at_nodes = (flux_x_at_x_interfaces[:, 1:] - flux_x_at_x_interfaces[:, :-1]) / dx\n",
    "\n",
    "    # Difference Fy across the node in y-direction\n",
    "    # flux_y_at_y_interfaces[I, J] is the flux on the top interface of node (I,J)\n",
    "    # flux_y_at_y_interfaces[I, J-1] is the flux on the bottom interface of node (I,J)\n",
    "    # We need these for I=1..nx (inner nodes plus boundaries in x)\n",
    "    dFy_dy_at_nodes = (flux_y_at_y_interfaces[1:, :] - flux_y_at_y_interfaces[:-1, :]) / dy\n",
    "\n",
    "    # Check shapes - these differences should be on the inner nodes grid\n",
    "    if dFx_dx_at_nodes.shape != (nx, ny):\n",
    "        raise RuntimeError(f\"Internal error: dFx_dx shape {dFx_dx_at_nodes.shape} unexpected.\")\n",
    "    if dFy_dy_at_nodes.shape != (nx, ny):\n",
    "        raise RuntimeError(f\"Internal error: dFy_dy shape {dFy_dy_at_nodes.shape} unexpected.\")\n",
    "\n",
    "    # Sum the partial derivatives to get the divergence\n",
    "    divergence_at_inner_nodes = dFx_dx_at_nodes + dFy_dy_at_nodes\n",
    "\n",
    "    return divergence_at_inner_nodes"
   ],
   "id": "fb509db3597ac499"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_flux_on_interfaces(\n",
    "    grad_x_at_x_interfaces: np.ndarray,\n",
    "    grad_y_at_y_interfaces: np.ndarray,\n",
    "    C_tensor_at_interfaces: dict, # See details below\n",
    "    nx: int, ny: int\n",
    ") -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Calculates the vector flux F = C * grad(p) on the interfaces.\n",
    "\n",
    "    Args:\n",
    "        grad_x_at_x_interfaces (np.ndarray): dP/dx on x-interfaces, shape (nx, ny+1).\n",
    "        grad_y_at_y_interfaces (np.ndarray): dP/dy on y-interfaces, shape (nx+1, ny).\n",
    "        C_tensor_at_interfaces (dict): A dictionary containing the components\n",
    "            of the tensor C evaluated AT THE INTERFACES. Expected keys:\n",
    "            'cxx_x', 'cxy_x', 'cyx_x', 'cyy_x' (shape nx, ny+1) for x-interfaces.\n",
    "            'cxx_y', 'cxy_y', 'cyx_y', 'cyy_y' (shape nx+1, ny) for y-interfaces.\n",
    "            Calculating these C components accurately on interfaces from node/cell\n",
    "            data is a separate (crucial) step involving averaging/interpolation.\n",
    "        nx (int): Number of cells (inner nodes) in x direction.\n",
    "        ny (int): Number of cells (inner nodes) in y direction.\n",
    "\n",
    "    Returns:\n",
    "        tuple[np.ndarray, np.ndarray]:\n",
    "            - flux_x_at_x_interfaces: Fx component on x-interfaces, shape (nx, ny+1).\n",
    "            - flux_y_at_y_interfaces: Fy component on y-interfaces, shape (nx+1, ny).\n",
    "    \"\"\"\n",
    "    # Retrieve tensor components (assuming they exist and have correct shapes)\n",
    "    cxx_x = C_tensor_at_interfaces['cxx_x'] # (nx, ny+1)\n",
    "    cxy_x = C_tensor_at_interfaces['cxy_x'] # (nx, ny+1)\n",
    "    cyx_x = C_tensor_at_interfaces['cyx_x'] # (nx, ny+1)\n",
    "    cyy_x = C_tensor_at_interfaces['cyy_x'] # (nx, ny+1)\n",
    "\n",
    "    cxx_y = C_tensor_at_interfaces['cxx_y'] # (nx+1, ny)\n",
    "    cxy_y = C_tensor_at_interfaces['cxy_y'] # (nx+1, ny)\n",
    "    cyx_y = C_tensor_at_interfaces['cyx_y'] # (nx+1, ny)\n",
    "    cyy_y = C_tensor_at_interfaces['cyy_y'] # (nx+1, ny)\n",
    "\n",
    "    # We need grad_y at x-interfaces and grad_x at y-interfaces for the tensor product.\n",
    "    # Interpolate using simple averaging.\n",
    "    # Average grad_y[i,j] and grad_y[i+1,j] to get value at x-interface (i+1/2, j)\n",
    "    # Note: grad_y has shape (nx+1, ny)\n",
    "    grad_y_at_x_interfaces = 0.5 * (grad_y_at_y_interfaces[:-1, :] + grad_y_at_y_interfaces[1:, :]) # Shape (nx, ny)\n",
    "    # Need shape (nx, ny+1) - pad y-boundary? Or special handling?\n",
    "    # Let's assume for now we need values at all (nx, ny+1) x-interfaces.\n",
    "    # Simple padding might be okay if boundaries are handled appropriately in C or grad.\n",
    "    # Pad with nearest value (or zero, or extrapolate based on BCs)\n",
    "    grad_y_at_x_interfaces_padded = np.pad(grad_y_at_x_interfaces, ((0,0),(1,0)), mode='edge') # Pad bottom row\n",
    "    # Check if this padding makes sense physically based on the problem BCs!\n",
    "\n",
    "    # Average grad_x[i,j] and grad_x[i,j+1] to get value at y-interface (i, j+1/2)\n",
    "    # Note: grad_x has shape (nx, ny+1)\n",
    "    grad_x_at_y_interfaces = 0.5 * (grad_x_at_x_interfaces[:, :-1] + grad_x_at_x_interfaces[:, 1:]) # Shape (nx, ny)\n",
    "    # Need shape (nx+1, ny) - pad x-boundary?\n",
    "    grad_x_at_y_interfaces_padded = np.pad(grad_x_at_y_interfaces, ((1,0),(0,0)), mode='edge') # Pad left col\n",
    "\n",
    "    # Calculate Flux components on their respective interfaces\n",
    "    # Fx = Cxx * dPdx + Cxy * dPdy (@ x-interfaces)\n",
    "    flux_x = cxx_x * grad_x_at_x_interfaces + cxy_x * grad_y_at_x_interfaces_padded\n",
    "\n",
    "    # Fy = Cyx * dPdx + Cyy * dPdy (@ y-interfaces)\n",
    "    flux_y = cyx_y * grad_x_at_y_interfaces_padded + cyy_y * grad_y_at_y_interfaces\n",
    "\n",
    "    return flux_x, flux_y\n",
    "\n",
    "\n",
    "def laplacian_operator_action(p_nodal: np.ndarray,\n",
    "                              C_tensor_at_interfaces: dict,\n",
    "                              hcenter_inner: np.ndarray,\n",
    "                              diag_inv_inner: np.ndarray,\n",
    "                              dx: float, dy: float,\n",
    "                              nx: int, ny: int) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Computes the action of the anisotropic Helmholtz operator on p_nodal.\n",
    "    Operator: diag_inv * [∇ ⋅ (C ∇p) + hcenter * p]\n",
    "    Uses gradient_nodal_to_interface and divergence_interface_to_nodal.\n",
    "\n",
    "    Args:\n",
    "        p_nodal (np.ndarray): Nodal pressure field, shape (nx+1, ny+1).\n",
    "        C_tensor_at_interfaces (dict): Tensor C components defined on interfaces.\n",
    "                                     (See calculate_flux_on_interfaces docstring).\n",
    "        hcenter_inner (np.ndarray): Helmholtz coefficient at inner nodes, shape (nx, ny).\n",
    "        diag_inv_inner (np.ndarray): Final scaling factor at inner nodes, shape (nx, ny).\n",
    "        dx, dy (float): Grid spacing.\n",
    "        nx, ny (int): Inner dimensions.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Result of operator action on inner nodes, shape (nx, ny).\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Calculate gradient components on interfaces\n",
    "    grad_x, grad_y = gradient_nodal_to_interface(p_nodal, dx, dy, nx, ny)\n",
    "\n",
    "    # 2. Calculate flux F = C * grad(p) on interfaces\n",
    "    flux_x, flux_y = calculate_flux_on_interfaces(grad_x, grad_y, C_tensor_at_interfaces, nx, ny)\n",
    "\n",
    "    # 3. Calculate divergence of the flux at inner nodes\n",
    "    divergence_term = divergence_interface_to_nodal(flux_x, flux_y, dx, dy, nx, ny)\n",
    "\n",
    "    # 4. Add Helmholtz term\n",
    "    # Get p values at the inner nodes corresponding to the divergence output\n",
    "    p_inner_nodes = p_nodal[1:nx+1, 1:ny+1]\n",
    "    helmholtz_term = hcenter_inner * p_inner_nodes\n",
    "\n",
    "    # 5. Combine and apply diagonal scaling\n",
    "    lap_result = divergence_term + helmholtz_term\n",
    "    final_result = lap_result * diag_inv_inner # Element-wise multiplication\n",
    "\n",
    "    return final_result"
   ],
   "id": "32fe958253eb4816"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
