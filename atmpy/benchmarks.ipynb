{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T11:30:37.780932Z",
     "start_time": "2025-04-01T11:30:37.687315Z"
    }
   },
   "cell_type": "code",
   "source": "import numpy as np",
   "id": "9f35ff1f8999d0f0",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-01T11:32:42.517540Z",
     "start_time": "2025-04-01T11:32:42.512905Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ndim = 2\n",
    "rhs = np.arange(30).reshape((6, 5))\n",
    "igs = [2, 2]\n",
    "factor = 100\n",
    "wall_idx = np.empty((ndim), dtype=object)\n",
    "for dim in range(ndim):\n",
    "    wall_idx[dim] = slice(igs[dim], -igs[dim])\n",
    "print(rhs)\n",
    "for dim in range(ndim):\n",
    "    if True:\n",
    "        for direction in [-1, 1]:\n",
    "            wall_idx[dim] = (igs[dim] - 1) * direction\n",
    "            if direction == -1:\n",
    "                wall_idx[dim] -= 1\n",
    "            wall_idx_tuple = tuple(wall_idx)\n",
    "            rhs[wall_idx_tuple] *= factor\n",
    "            print(wall_idx_tuple)\n",
    "\n",
    "print(rhs)"
   ],
   "id": "b2e1fef74841a7b4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1  2  3  4]\n",
      " [ 5  6  7  8  9]\n",
      " [10 11 12 13 14]\n",
      " [15 16 17 18 19]\n",
      " [20 21 22 23 24]\n",
      " [25 26 27 28 29]]\n",
      "(-2, slice(2, -2, None))\n",
      "(1, slice(2, -2, None))\n",
      "(1, -2)\n",
      "(1, 1)\n",
      "[[   0    1    2    3    4]\n",
      " [   5  600  700  800    9]\n",
      " [  10   11   12   13   14]\n",
      " [  15   16   17   18   19]\n",
      " [  20   21 2200   23   24]\n",
      " [  25   26   27   28   29]]\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-27T19:17:23.134251Z",
     "start_time": "2025-03-27T19:17:23.125507Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def euler_backward_non_advective_impl_part(Sol, mpv, elem, node, ud, th, t, dt, alpha_diff, Sol0 = None, writer = None, label=None, debug=False):\n",
    "    nc = node.sc\n",
    "    rhs = mpv.rhs\n",
    "\n",
    "    if Sol0 is not None:\n",
    "        bdry.set_explicit_boundary_data(Sol0, elem, ud, th, mpv)\n",
    "        operator_coefficients_nodes(elem, node, Sol0, mpv, ud, th, dt)\n",
    "    else:\n",
    "        bdry.set_explicit_boundary_data(Sol, elem, ud, th, mpv)\n",
    "        operator_coefficients_nodes(elem, node, Sol, mpv, ud, th, dt)\n",
    "\n",
    "    bdry.set_ghostnodes_p2(mpv.p2_nodes,node,ud)\n",
    "    correction_nodes(Sol,elem,node,mpv,mpv.p2_nodes,dt,ud,th,0)\n",
    "    bdry.set_explicit_boundary_data(Sol, elem, ud, th, mpv)\n",
    "\n",
    "    rhs[...] = divergence_nodes(rhs,elem,node,Sol,ud)\n",
    "\n",
    "    rhs /= dt\n",
    "\n",
    "    if ud.is_compressible == 0:\n",
    "        if ud.is_ArakawaKonor:\n",
    "            rhs -= mpv.wcenter * mpv.dp2_nodes\n",
    "            mpv.wcenter[...] = 0.0\n",
    "        else:\n",
    "            mpv.wcenter[...] *= ud.compressibility\n",
    "    else:\n",
    "        mpv.wcenter *= ud.compressibility\n",
    "\n",
    "    mpv.rhs[...] = rhs\n",
    "\n",
    "    VS = True\n",
    "\n",
    "    # prepare initial left-hand side and the laplacian stencil\n",
    "    if elem.ndim == 2:\n",
    "        Vec = mpv\n",
    "        coriolis_params = multiply_inverse_coriolis(Vec, Sol, mpv, ud, elem, node, dt, attrs=('u', 'v', 'w'), get_coeffs = True)\n",
    "        # lap = stencil_9pt(elem,node,mpv,Sol,ud,diag_inv,dt,coriolis_params)\n",
    "        # sh = (ud.inx)*(ud.iny)\n",
    "\n",
    "        diag_inv = lm_lp.precon_diag_prepare(mpv, elem, node, ud, coriolis_params)\n",
    "        rhs *= diag_inv\n",
    "\n",
    "        p2 = mpv.p2_nodes[node.i2].T\n",
    "        lap = lm_lp.stencil_9pt_numba_test(mpv,node,coriolis_params,diag_inv, ud)\n",
    "        sh = p2.shape[0] * p2.shape[1]\n",
    "\n",
    "    elif elem.ndim == 3 and elem.icy - 2*elem.igs[1] <= 2:\n",
    "        # horizontal slice hack\n",
    "        p2 = np.copy(mpv.p2_nodes[1:-1,elem.igs[1],1:-1])\n",
    "        lap = lm_lp.stencil_hs(elem,node,mpv,ud,diag_inv,dt)\n",
    "        sh = p2.reshape(-1).shape[0]\n",
    "\n",
    "    elif elem.ndim == 3 and elem.iicy > 1 and elem.iicz == 1:\n",
    "        # vertical slice hack\n",
    "\n",
    "        if not VS:\n",
    "            lap = lm_lp.stencil_vs(elem,node,mpv,ud,diag_inv,dt)\n",
    "            sh = (node.iicx)*(node.iicy)\n",
    "        if VS:\n",
    "            p2 = np.copy(mpv.p2_nodes[1:-1,1:-1,elem.igs[2]])\n",
    "            lap = lm_lp.stencil_vs(elem,node,mpv,ud,diag_inv,dt)\n",
    "            sh = p2.reshape(-1).shape[0]\n",
    "\n",
    "    elif elem.ndim == 3 and elem.icy - 2*elem.igs[1] > 2:\n",
    "        lap = lm_lp.stencil_27pt(elem,node,mpv,ud,diag_inv,dt)\n",
    "        sh = p2.reshape(-1).shape[0]\n",
    "\n",
    "    lap = sp.sparse.linalg.LinearOperator((sh,sh),lap)\n",
    "    # lap = LinearOperator(sh,lap)\n",
    "\n",
    "    counter = solver_counter()\n",
    "\n",
    "    # prepare right-hand side\n",
    "    if elem.ndim == 2:\n",
    "        rhs_inner = rhs[1:-1,1:-1].T.ravel()\n",
    "    elif elem.ndim == 3 and elem.iicy > 1 and elem.iicz == 1:\n",
    "\n",
    "        if not VS:\n",
    "            rhs_inner = rhs[...,elem.igs[2]][node.igx:-node.igx,node.igy:-node.igy].ravel()\n",
    "        if VS:\n",
    "            rhs_inner = rhs[1:-1,1:-1,elem.igs[2]].ravel()\n",
    "\n",
    "    elif elem.ndim == 3 and elem.icy - 2*elem.igs[1] > 2:\n",
    "        rhs_inner = rhs[1:-1,1:-1,1:-1].ravel()\n",
    "    else:\n",
    "        rhs_inner = rhs[1:-1,elem.igs[1],1:-1].ravel()\n",
    "\n",
    "    p2, _ = sp.sparse.linalg.bicgstab(lap,rhs_inner,tol=ud.tol,maxiter=ud.max_iterations,callback=counter)\n",
    "\n",
    "    global total_calls, total_iter\n",
    "    total_iter += counter.niter\n",
    "    total_calls += 1\n",
    "    p2_full = np.zeros(nc).squeeze()\n",
    "    if elem.ndim == 2:\n",
    "        p2_full[node.i2] = p2.reshape(rhs[node.i1].shape[1],rhs[node.i1].shape[0]).T\n",
    "    elif elem.ndim == 3 and elem.icy - 2*elem.igs[1] <= 2:\n",
    "        # horizontal slice hack\n",
    "        p2 = p2.reshape(ud.inx+2, ud.inz+2)\n",
    "        p2 = np.expand_dims(p2,1)\n",
    "        p2 = np.repeat(p2, node.icy, axis=1)\n",
    "        p2_full[1:-1,:,1:-1] = p2\n",
    "    elif elem.ndim == 3 and elem.iicy > 1 and elem.iicz == 1:\n",
    "        if not VS:\n",
    "            p2 = p2.reshape(node.iicx,node.iicy)\n",
    "            p2 = np.repeat(p2[...,np.newaxis], node.icz, axis=2)\n",
    "            p2_full[node.igx:-node.igx,node.igy:-node.igy] = p2\n",
    "        if VS:\n",
    "            p2 = p2.reshape(ud.inx+2, ud.iny+2)\n",
    "            p2 = np.expand_dims(p2,2)\n",
    "            p2 = np.repeat(p2, node.icz, axis=2)\n",
    "            p2_full[1:-1,1:-1,:] = p2\n",
    "\n",
    "    elif elem.ndim == 3 and elem.icy - 2*elem.igs[1] > 2:\n",
    "        p2_full[1:-1,1:-1,1:-1] = p2.reshape(ud.inx+2,ud.iny+2,ud.inz+2)\n",
    "\n",
    "    bdry.set_ghostnodes_p2(p2_full,node,ud)\n",
    "    correction_nodes(Sol,elem,node,mpv,p2_full,dt,ud,th,1)\n",
    "\n",
    "    mpv.p2_nodes[...] += p2_full\n",
    "    bdry.set_ghostnodes_p2(mpv.p2_nodes,node,ud)\n",
    "    bdry.set_explicit_boundary_data(Sol, elem, ud, th, mpv)\n"
   ],
   "id": "c5ab0b0693af4f2d",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "import numba as nb",
   "id": "5202f45ffb4bbc44"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T12:38:59.325393Z",
     "start_time": "2025-04-11T12:38:57.121933Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def stencil_9pt(elem,node,mpv,Sol,ud,diag_inv,dt,coriolis_params):\n",
    "    igx = elem.igx\n",
    "    igy = elem.igy\n",
    "\n",
    "    icxn = node.icx\n",
    "    icyn = node.icy\n",
    "\n",
    "    iicxn = icxn - (2 * igx)\n",
    "    iicyn = icyn - (2 * igy)\n",
    "\n",
    "    iicxn, iicyn = iicyn, iicxn\n",
    "\n",
    "    dx = node.dy\n",
    "    dy = node.dx\n",
    "\n",
    "    inner_domain = (slice(igx,-igx),slice(igy,-igy))\n",
    "    i1 = node.i1\n",
    "\n",
    "    hplusx = mpv.wplus[1][i1].reshape(-1,)\n",
    "    hplusy = mpv.wplus[0][i1].reshape(-1,)\n",
    "    hcenter = mpv.wcenter[i1].reshape(-1,)\n",
    "\n",
    "    diag_inv = diag_inv[i1].reshape(-1,)\n",
    "\n",
    "    oodx = 1.0 / (dx)\n",
    "    oody = 1.0 / (dy)\n",
    "\n",
    "    x_periodic = ud.bdry_type[1] == opts.BdryType.PERIODIC\n",
    "    y_periodic = ud.bdry_type[0] == opts.BdryType.PERIODIC\n",
    "\n",
    "    x_wall = ud.bdry_type[1] == opts.BdryType.WALL or ud.bdry_type[1] == opts.BdryType.RAYLEIGH\n",
    "    y_wall = ud.bdry_type[0] == opts.BdryType.WALL or ud.bdry_type[0] == opts.BdryType.RAYLEIGH\n",
    "    return lambda p : lap2D_gather(p, igx,igy, iicxn, iicyn, hplusx, hplusy, hcenter, oodx, oody, x_periodic, y_periodic, x_wall, y_wall, diag_inv, coriolis_params)\n",
    "\n",
    "@nb.jit(nopython=True, nogil=False, cache=True)\n",
    "def lap2D_gather(p, igx,igy, iicxn, iicyn, hplusx, hplusy, hcenter, oodx, oody, x_periodic, y_periodic, x_wall, y_wall, diag_inv, coriolis):\n",
    "    ngnc = (iicxn) * (iicyn)\n",
    "    lap = np.zeros((ngnc))\n",
    "    cnt_x = 0\n",
    "    cnt_y = 0\n",
    "\n",
    "    nine_pt = 0.25 * (2.0) * 1.0\n",
    "    cyy, cxx, cyx, cxy = coriolis\n",
    "    oodx2 = 0.5 * oodx**2\n",
    "    oody2 = 0.5 * oody**2\n",
    "\n",
    "    for idx in range(iicxn * iicyn):\n",
    "        ne_topleft = idx - iicxn - 1\n",
    "        ne_topright = idx - iicxn\n",
    "        ne_botleft = idx - 1\n",
    "        ne_botright = idx\n",
    "\n",
    "        # get indices of the 9pt stencil\n",
    "        topleft_idx = idx - iicxn - 1\n",
    "        midleft_idx = idx - 1\n",
    "        botleft_idx = idx + iicxn - 1\n",
    "\n",
    "        topmid_idx = idx - iicxn\n",
    "        midmid_idx = idx\n",
    "        botmid_idx = idx + iicxn\n",
    "\n",
    "        topright_idx = idx - iicxn + 1\n",
    "        midright_idx = idx + 1\n",
    "        botright_idx = idx + iicxn + 1\n",
    "\n",
    "        if cnt_x == 0:\n",
    "            topleft_idx += iicxn - 1\n",
    "            midleft_idx += iicxn - 1\n",
    "            botleft_idx += iicxn - 1\n",
    "\n",
    "            ne_topleft += iicxn - 1\n",
    "            ne_botleft += iicxn - 1\n",
    "\n",
    "        if cnt_x == (iicxn - 1):\n",
    "            topright_idx -= iicxn - 1\n",
    "            midright_idx -= iicxn - 1\n",
    "            botright_idx -= iicxn - 1\n",
    "\n",
    "            ne_topright -= iicxn - 1\n",
    "            ne_botright -= iicxn - 1\n",
    "\n",
    "        if cnt_y == 0:\n",
    "            topleft_idx += ((iicxn) * (iicyn - 1))\n",
    "            topmid_idx += ((iicxn) * (iicyn - 1))\n",
    "            topright_idx += ((iicxn) * (iicyn - 1))\n",
    "\n",
    "            ne_topleft += ((iicxn) * (iicyn - 1))\n",
    "            ne_topright += ((iicxn) * (iicyn - 1))\n",
    "\n",
    "        if cnt_y == (iicyn - 1):\n",
    "            botleft_idx -= ((iicxn) * (iicyn - 1))\n",
    "            botmid_idx -= ((iicxn) * (iicyn - 1))\n",
    "            botright_idx -= ((iicxn) * (iicyn - 1))\n",
    "\n",
    "            ne_botleft -= ((iicxn) * (iicyn - 1))\n",
    "            ne_botright -= ((iicxn) * (iicyn - 1))\n",
    "\n",
    "        topleft = p[topleft_idx]\n",
    "        midleft = p[midleft_idx]\n",
    "        botleft = p[botleft_idx]\n",
    "\n",
    "        topmid = p[topmid_idx]\n",
    "        midmid = p[midmid_idx]\n",
    "        botmid = p[botmid_idx]\n",
    "\n",
    "        topright = p[topright_idx]\n",
    "        midright = p[midright_idx]\n",
    "        botright = p[botright_idx]\n",
    "\n",
    "        hplusx_topleft = hplusx[ne_topleft]\n",
    "        hplusx_botleft = hplusx[ne_botleft]\n",
    "        hplusy_topleft = hplusy[ne_topleft]\n",
    "        hplusy_botleft = hplusy[ne_botleft]\n",
    "\n",
    "        hplusx_topright = hplusx[ne_topright]\n",
    "        hplusx_botright = hplusx[ne_botright]\n",
    "        hplusy_topright = hplusy[ne_topright]\n",
    "        hplusy_botright = hplusy[ne_botright]\n",
    "\n",
    "        cxx_tl  = cxx[ne_topleft]\n",
    "        cxx_tr = cxx[ne_topright]\n",
    "        cxx_bl  = cxx[ne_botleft]\n",
    "        cxx_br = cxx[ne_botright]\n",
    "\n",
    "        cxy_tl  = cxy[ne_topleft]\n",
    "        cxy_tr  = cxy[ne_topright]\n",
    "        cxy_bl  = cxy[ne_botleft]\n",
    "        cxy_br  = cxy[ne_botright]\n",
    "\n",
    "        cyx_tl  = cyx[ne_topleft]\n",
    "        cyx_tr  = cyx[ne_topright]\n",
    "        cyx_bl  = cyx[ne_botleft]\n",
    "        cyx_br  = cyx[ne_botright]\n",
    "\n",
    "        cyy_tl  = cyy[ne_topleft]\n",
    "        cyy_tr  = cyy[ne_topright]\n",
    "        cyy_bl  = cyy[ne_botleft]\n",
    "        cyy_br  = cyy[ne_botright]\n",
    "\n",
    "        Dx_tl = 0.5 * (topmid   - topleft + midmid   - midleft) * hplusx_topleft\n",
    "        Dx_tr = 0.5 * (topright - topmid  + midright - midmid ) * hplusx_topright\n",
    "        Dx_bl = 0.5 * (botmid   - botleft + midmid   - midleft) * hplusx_botleft\n",
    "        Dx_br = 0.5 * (botright - botmid  + midright - midmid ) * hplusx_botright\n",
    "\n",
    "        Dy_tl = 0.5 * (midmid   - topmid   + midleft - topleft) * hplusy_topleft\n",
    "        Dy_tr = 0.5 * (midright - topright + midmid  - topmid ) * hplusy_topright\n",
    "        Dy_bl = 0.5 * (botmid   - midmid   + botleft - midleft) * hplusy_botleft\n",
    "        Dy_br = 0.5 * (botright - midright + botmid  - midmid ) * hplusy_botright\n",
    "\n",
    "        fac = 1.0\n",
    "        Dxx = 0.5 * (cxx_tr * Dx_tr - cxx_tl * Dx_tl + cxx_br * Dx_br - cxx_bl * Dx_bl) * oodx * oodx * fac\n",
    "        Dyy = 0.5 * (cyy_br * Dy_br - cyy_tr * Dy_tr + cyy_bl * Dy_bl - cyy_tl * Dy_tl) * oody * oody * fac\n",
    "        Dyx = 0.5 * (cyx_br * Dy_br - cyx_bl * Dy_bl + cyx_tr * Dy_tr - cyx_tl * Dy_tl) * oody * oodx * fac\n",
    "        Dxy = 0.5 * (cxy_br * Dx_br - cxy_tr * Dx_tr + cxy_bl * Dy_bl - cxy_tl * Dx_tl) * oodx * oody * fac\n",
    "\n",
    "\n",
    "        lap[idx] = Dxx + Dyy + Dyx + Dxy + hcenter[idx] * p[idx]\n"
   ],
   "id": "a91aa8eac63605a7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm of difference: 7.038508264717789\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T13:49:02.132736Z",
     "start_time": "2025-04-11T13:49:02.118597Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import numba as nb\n",
    "\n",
    "# Define constants for clarity\n",
    "HALF = 0.5\n",
    "\n",
    "@nb.jit(nopython=True, nogil=True, cache=True, fastmath=False) # nogil=True should be safe\n",
    "def lap2D_gather_refactored_numba(\n",
    "    p_node: np.ndarray,      # Input pressure vector (flattened internal nodes)\n",
    "    iicxn: int,              # Number of internal nodes in x\n",
    "    iicyn: int,              # Number of internal nodes in y\n",
    "    hplusx_elem: np.ndarray, # Coefficient array (ELEMENT-centered or face-centered)\n",
    "    hplusy_elem: np.ndarray, # Coefficient array (ELEMENT-centered or face-centered)\n",
    "    hcenter_node: np.ndarray,# Coefficient array (NODE-centered)\n",
    "    oodx: float,             # 1 / dx\n",
    "    oody: float,             # 1 / dy\n",
    "    x_periodic: bool,        # Boolean or int flag\n",
    "    y_periodic: bool,        # Boolean or int flag\n",
    "    x_wall: bool,            # Boolean or int flag\n",
    "    y_wall: bool,            # Boolean or int flag\n",
    "    diag_inv_node: np.ndarray,# Diagonal preconditioner (NODE-centered)\n",
    "    coriolis_elem: tuple,    # Tuple of ELEMENT-centered coeff arrays (cyy, cxx, cyx, cxy)\n",
    "    out: np.ndarray = None   # Optional output array for in-place operation\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calculates the action of a 2D discretized operator (Laplacian + Coriolis)\n",
    "    on a vector 'p_node' using a 9-point stencil (matrix-free via Numba).\n",
    "\n",
    "    Handles periodic and wall boundary conditions by adjusting coefficients.\n",
    "    Operates on flattened arrays corresponding to internal grid nodes/elements.\n",
    "\n",
    "    Args:\n",
    "        p_node: Flattened 1D array of input values at internal nodes.\n",
    "        iicxn, iicyn: Internal grid dimensions (number of nodes).\n",
    "        hplusx_elem, hplusy_elem: Coefficient arrays, assumed mapped to elements\n",
    "                                 (e.g., indexed by bottom-left node's internal index).\n",
    "                                 Size should match number of internal elements.\n",
    "        hcenter_node: Central coefficient at each internal node. Size ngnc.\n",
    "        oodx, oody: Grid spacing reciprocals.\n",
    "        x_periodic, y_periodic: Flags for periodic boundaries.\n",
    "        x_wall, y_wall: Flags for wall boundaries (assumed zero Neumann).\n",
    "        diag_inv_node: Diagonal preconditioning values at each internal node. Size ngnc.\n",
    "        coriolis_elem: Tuple (cyy, cxx, cyx, cxy) of coefficient arrays,\n",
    "                       assumed mapped to elements.\n",
    "        out: Optional pre-allocated array (size ngnc) to store the result.\n",
    "\n",
    "    Returns:\n",
    "        A 1D numpy array (size ngnc) containing the result of the operator\n",
    "        applied to p_node. If 'out' was provided, it returns 'out'.\n",
    "    \"\"\"\n",
    "    ngnc = iicxn * iicyn # Total number of internal nodes\n",
    "\n",
    "    # Initialize output array\n",
    "    if out is None:\n",
    "        lap_node = np.zeros(ngnc, dtype=p_node.dtype)\n",
    "    else:\n",
    "        # Ensure the output array has the correct shape if provided\n",
    "        if out.shape[0] != ngnc:\n",
    "            # Numba doesn't support raising exceptions easily, maybe return zeros or handle outside\n",
    "            return np.zeros(ngnc, dtype=p_node.dtype) # Indicate error state\n",
    "        lap_node = out\n",
    "        lap_node[:] = 0.0 # Zero out array if accumulating isn't desired\n",
    "\n",
    "    # Unpack Coriolis terms for clarity\n",
    "    cyy_elem, cxx_elem, cyx_elem, cxy_elem = coriolis_elem\n",
    "\n",
    "    # Use nested loops for better 2D clarity\n",
    "    for j in range(iicyn):  # Loop over y index (internal nodes, 0 to iicyn-1)\n",
    "        for i in range(iicxn):  # Loop over x index (internal nodes, 0 to iicxn-1)\n",
    "            # --- Calculate current node index ---\n",
    "            idx_mid = j * iicxn + i\n",
    "\n",
    "            # --- Determine neighbor node coordinates (ni, nj) with periodic wrapping ---\n",
    "            # Note: Python's % handles negative numbers correctly for wrapping in Numba too\n",
    "            i_w = (i - 1 + iicxn) % iicxn if x_periodic else i - 1\n",
    "            i_e = (i + 1) % iicxn         if x_periodic else i + 1\n",
    "            j_s = (j - 1 + iicyn) % iicyn if y_periodic else j - 1\n",
    "            j_n = (j + 1) % iicyn         if y_periodic else j + 1\n",
    "\n",
    "            # --- Calculate flattened neighbor indices in 'p_node' array ---\n",
    "            # These indices are potentially invalid if walls are present,\n",
    "            # but we fetch p values first and apply BCs via coefficients later.\n",
    "            idx_mm = idx_mid           # Middle-Middle (center)\n",
    "            idx_wm = j * iicxn + i_w   # West-Middle\n",
    "            idx_em = j * iicxn + i_e   # East-Middle\n",
    "            idx_ms = j_s * iicxn + i   # Middle-South\n",
    "            idx_mn = j_n * iicxn + i   # Middle-North\n",
    "            idx_ws = j_s * iicxn + i_w # West-South\n",
    "            idx_es = j_s * iicxn + i_e # East-South\n",
    "            idx_wn = j_n * iicxn + i_w # West-North\n",
    "            idx_en = j_n * iicxn + i_e # East-North\n",
    "\n",
    "            # --- Boundary Checks for Non-Periodic Walls ---\n",
    "            # These flags determine if a neighbor is *logically* outside a wall\n",
    "            on_west_boundary  = (not x_periodic and i == 0)\n",
    "            on_east_boundary  = (not x_periodic and i == iicxn - 1)\n",
    "            on_south_boundary = (not y_periodic and j == 0)\n",
    "            on_north_boundary = (not y_periodic and j == iicyn - 1)\n",
    "\n",
    "            # --- Gather 'p' values from neighbors ---\n",
    "            # For wall boundaries, fetch the value from the boundary node itself (p[idx_mid])\n",
    "            # This effectively applies the Neumann BC when combined with zeroed coefficients later.\n",
    "            p_mm = p_node[idx_mm]\n",
    "            p_wm = p_node[idx_wm if not on_west_boundary else idx_mm]\n",
    "            p_em = p_node[idx_em if not on_east_boundary else idx_mm]\n",
    "            p_ms = p_node[idx_ms if not on_south_boundary else idx_mm]\n",
    "            p_mn = p_node[idx_mn if not on_north_boundary else idx_mm]\n",
    "\n",
    "            p_ws = p_node[idx_ws if not (on_west_boundary or on_south_boundary) else idx_mm]\n",
    "            p_es = p_node[idx_es if not (on_east_boundary or on_south_boundary) else idx_mm]\n",
    "            p_wn = p_node[idx_wn if not (on_west_boundary or on_north_boundary) else idx_mm]\n",
    "            p_en = p_node[idx_en if not (on_east_boundary or on_north_boundary) else idx_mm]\n",
    "\n",
    "\n",
    "            # --- Determine element indices for coefficients ---\n",
    "            # Assuming coeffs arrays (hplus, coriolis) are mapped based on the\n",
    "            # bottom-left node's *internal* index.\n",
    "            # Calculate the potential indices of the 4 surrounding elements' bottom-left nodes.\n",
    "            # Need to handle periodicity/walls for these indices if coeff arrays only store internal elements.\n",
    "            elem_idx_sw = ((j - 1 + iicyn) % iicyn if y_periodic else j - 1) * iicxn + \\\n",
    "                          ((i - 1 + iicxn) % iicxn if x_periodic else i - 1)\n",
    "            elem_idx_se = ((j - 1 + iicyn) % iicyn if y_periodic else j - 1) * iicxn + \\\n",
    "                          (i % iicxn if x_periodic else i) # Use i directly for SE/NE x-index\n",
    "            elem_idx_nw = (j % iicyn if y_periodic else j) * iicxn + \\\n",
    "                          ((i - 1 + iicxn) % iicxn if x_periodic else i - 1)\n",
    "            elem_idx_ne = (j % iicyn if y_periodic else j) * iicxn + \\\n",
    "                          (i % iicxn if x_periodic else i) # Current node (j,i) is bottom-left of NE element\n",
    "\n",
    "            # --- Gather Coefficients (hplus, coriolis) ---\n",
    "            # Use helper function to safely get coefficients, handling potential\n",
    "            # out-of-bounds access for wall boundaries by returning 0.0\n",
    "\n",
    "            # SW Element Coefficients\n",
    "            valid_sw = (not (on_west_boundary or on_south_boundary))\n",
    "            hpx_sw = hplusx_elem[elem_idx_sw] if valid_sw else 0.0\n",
    "            hpy_sw = hplusy_elem[elem_idx_sw] if valid_sw else 0.0\n",
    "            cxx_sw = cxx_elem[elem_idx_sw] if valid_sw else 0.0\n",
    "            cyy_sw = cyy_elem[elem_idx_sw] if valid_sw else 0.0\n",
    "            cxy_sw = cxy_elem[elem_idx_sw] if valid_sw else 0.0\n",
    "            cyx_sw = cyx_elem[elem_idx_sw] if valid_sw else 0.0\n",
    "\n",
    "            # SE Element Coefficients\n",
    "            valid_se = (not (on_east_boundary or on_south_boundary))\n",
    "            hpx_se = hplusx_elem[elem_idx_se] if valid_se else 0.0\n",
    "            hpy_se = hplusy_elem[elem_idx_se] if valid_se else 0.0\n",
    "            cxx_se = cxx_elem[elem_idx_se] if valid_se else 0.0\n",
    "            cyy_se = cyy_elem[elem_idx_se] if valid_se else 0.0\n",
    "            cxy_se = cxy_elem[elem_idx_se] if valid_se else 0.0\n",
    "            cyx_se = cyx_elem[elem_idx_se] if valid_se else 0.0\n",
    "\n",
    "            # NW Element Coefficients\n",
    "            valid_nw = (not (on_west_boundary or on_north_boundary))\n",
    "            hpx_nw = hplusx_elem[elem_idx_nw] if valid_nw else 0.0\n",
    "            hpy_nw = hplusy_elem[elem_idx_nw] if valid_nw else 0.0\n",
    "            cxx_nw = cxx_elem[elem_idx_nw] if valid_nw else 0.0\n",
    "            cyy_nw = cyy_elem[elem_idx_nw] if valid_nw else 0.0\n",
    "            cxy_nw = cxy_elem[elem_idx_nw] if valid_nw else 0.0\n",
    "            cyx_nw = cyx_elem[elem_idx_nw] if valid_nw else 0.0\n",
    "\n",
    "            # NE Element Coefficients\n",
    "            valid_ne = (not (on_east_boundary or on_north_boundary))\n",
    "            hpx_ne = hplusx_elem[elem_idx_ne] if valid_ne else 0.0\n",
    "            hpy_ne = hplusy_elem[elem_idx_ne] if valid_ne else 0.0\n",
    "            cxx_ne = cxx_elem[elem_idx_ne] if valid_ne else 0.0\n",
    "            cyy_ne = cyy_elem[elem_idx_ne] if valid_ne else 0.0\n",
    "            cxy_ne = cxy_elem[elem_idx_ne] if valid_ne else 0.0\n",
    "            cyx_ne = cyx_elem[elem_idx_ne] if valid_ne else 0.0\n",
    "\n",
    "            # --- Calculate fluxes / derivatives (using gathered p and coeffs) ---\n",
    "            # These coefficients (hpx_*, cxx_*, etc.) are now correctly zeroed\n",
    "            # if they correspond to an element outside a wall boundary.\n",
    "            Dx_tl = HALF * (p_mn - p_wn + p_mm - p_wm) * hpx_nw # Top-Left face flux approx\n",
    "            Dx_tr = HALF * (p_en - p_mn + p_em - p_mm) * hpx_ne # Top-Right face flux approx\n",
    "            Dx_bl = HALF * (p_mm - p_wm + p_ms - p_ws) * hpx_sw # Bottom-Left face flux approx\n",
    "            Dx_br = HALF * (p_em - p_mm + p_es - p_ms) * hpx_se # Bottom-Right face flux approx\n",
    "\n",
    "            Dy_tl = HALF * (p_mm - p_mn + p_wm - p_wn) * hpy_nw # Top-Left face flux approx\n",
    "            Dy_tr = HALF * (p_em - p_en + p_mm - p_mn) * hpy_ne # Top-Right face flux approx\n",
    "            Dy_bl = HALF * (p_ms - p_mm + p_ws - p_wm) * hpy_sw # Bottom-Left face flux approx\n",
    "            Dy_br = HALF * (p_es - p_em + p_ms - p_mm) * hpy_se # Bottom-Right face flux approx\n",
    "\n",
    "            # --- Combine terms for the operator action at 'idx_mid' ---\n",
    "            # Based on divergence form: d/dx(F_x) + d/dy(F_y)\n",
    "            # F_x approx = cxx * Dx + cxy * Dy\n",
    "            # F_y approx = cyx * Dx + cyy * Dy\n",
    "            # d/dx(F_x) approx = ( F_x_east_face - F_x_west_face ) * oodx\n",
    "            # d/dy(F_y) approx = ( F_y_north_face - F_y_south_face ) * oody\n",
    "\n",
    "            # Approximate fluxes at cell faces around node (i,j)\n",
    "            Fx_west = HALF * (cxx_sw * Dx_bl + cxx_nw * Dx_tl + cxy_sw * Dy_bl + cxy_nw * Dy_tl)\n",
    "            Fx_east = HALF * (cxx_se * Dx_br + cxx_ne * Dx_tr + cxy_se * Dy_br + cxy_ne * Dy_tr)\n",
    "            Fy_south = HALF * (cyx_sw * Dx_bl + cyx_se * Dx_br + cyy_sw * Dy_bl + cyy_se * Dy_br)\n",
    "            Fy_north = HALF * (cyx_nw * Dx_tl + cyx_ne * Dx_tr + cyy_nw * Dy_tl + cyy_ne * Dy_tr)\n",
    "\n",
    "            divergence = (Fx_east - Fx_west) * oodx + (Fy_north - Fy_south) * oody\n",
    "\n",
    "            # --- Final value for the node ---\n",
    "            # Check if the original formula includes the hcenter term *before* or *after* divergence.\n",
    "            # Assuming it's added:\n",
    "            lap_val = divergence + hcenter_node[idx_mid] * p_mm\n",
    "\n",
    "            # Apply diagonal preconditioner\n",
    "            lap_node[idx_mid] = lap_val * diag_inv_node[idx_mid]\n",
    "\n",
    "    return lap_node"
   ],
   "id": "11f5038a1e263ca9",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T13:50:22.322426Z",
     "start_time": "2025-04-11T13:50:22.302073Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import sys\n",
    "#\n",
    "# # --- Assume functions are defined/imported ---\n",
    "# # Make sure these placeholder functions have the EXACT same signature\n",
    "# # as your actual functions. Replace the imports/definitions below.\n",
    "#\n",
    "# # Placeholder for the ORIGINAL Numba function\n",
    "# try:\n",
    "#     # Option 1: If it's in a file named, e.g., original_laplacian.py\n",
    "#     from original_laplacian import lap2D_gather as lap2D_gather_original\n",
    "#     print(\"Imported lap2D_gather_original from original_laplacian.py\")\n",
    "# except ImportError:\n",
    "#     print(\"Warning: Could not import lap2D_gather_original. Using placeholder.\")\n",
    "#     # Option 2: Define a dummy placeholder if the real one isn't available\n",
    "#     # This will likely fail comparisons but allows the script structure to run.\n",
    "#     import numba as nb\n",
    "#     @nb.jit(nopython=True)\n",
    "#     def lap2D_gather_original(p, igx,igy, iicxn, iicyn, hplusx, hplusy, hcenter, oodx, oody, x_periodic, y_periodic, x_wall, y_wall, diag_inv, coriolis):\n",
    "#         # This placeholder just returns zeros - REPLACE IT with your original code\n",
    "#         # Note: The signature must match EXACTLY, including parameter names if\n",
    "#         # the original code relied on them implicitly (though less likely in Numba).\n",
    "#         # The dummy 'igx', 'igy' are included here assuming they were in the original\n",
    "#         # even if unused, to maintain the signature for the call.\n",
    "#         ngnc = iicxn * iicyn\n",
    "#         return np.zeros(ngnc, dtype=p.dtype)\n",
    "#\n",
    "# # Placeholder for the NEW Refactored Numba function\n",
    "# try:\n",
    "#     # Option 1: If it's in a file named, e.g., refactored_laplacian.py\n",
    "#     from refactored_laplacian import lap2D_gather_refactored_numba\n",
    "#     print(\"Imported lap2D_gather_refactored_numba from refactored_laplacian.py\")\n",
    "# except ImportError:\n",
    "#     print(\"Warning: Could not import lap2D_gather_refactored_numba. Using placeholder.\")\n",
    "#     # Option 2: Define a dummy placeholder\n",
    "#     import numba as nb\n",
    "#     @nb.jit(nopython=True)\n",
    "#     def lap2D_gather_refactored_numba(p_node: np.ndarray, iicxn: int, iicyn: int, hplusx_elem: np.ndarray, hplusy_elem: np.ndarray, hcenter_node: np.ndarray, oodx: float, oody: float, x_periodic: bool, y_periodic: bool, x_wall: bool, y_wall: bool, diag_inv_node: np.ndarray, coriolis_elem: tuple, out: np.ndarray = None):\n",
    "#         # This placeholder just returns zeros - REPLACE IT with your refactored code\n",
    "#         ngnc = iicxn * iicyn\n",
    "#         if out is None:\n",
    "#             out = np.zeros(ngnc, dtype=p_node.dtype)\n",
    "#         else:\n",
    "#             out[:] = 0.0\n",
    "#         return out\n",
    "# # --- End Placeholder functions ---\n",
    "\n",
    "\n",
    "def run_numba_comparison(iicxn, iicyn, num_trials=10):\n",
    "    \"\"\"\n",
    "    Compares the original and refactored Numba implementations.\n",
    "    \"\"\"\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"Running comparison for grid size: {iicxn} x {iicyn}\")\n",
    "    print(f\"Number of trials for timing: {num_trials}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    ngnc = iicxn * iicyn # Number of internal grid nodes\n",
    "    nelem = iicxn * iicyn # Assuming element count matches internal nodes\n",
    "    # Dummy ghost cell info if needed by original signature (adjust if different)\n",
    "    igx, igy = 2, 2\n",
    "\n",
    "    # --- Generate Consistent Random Test Data (CPU) ---\n",
    "    np.random.seed(42)\n",
    "    p_np = np.random.rand(ngnc).astype(np.float64)\n",
    "    hplusx_np = np.random.rand(nelem).astype(np.float64) + 0.1\n",
    "    hplusy_np = np.random.rand(nelem).astype(np.float64) + 0.1\n",
    "    hcenter_np = np.random.rand(ngnc).astype(np.float64) * 5.0 + 1.0\n",
    "    diag_inv_np = (1.0 / hcenter_np).astype(np.float64)\n",
    "    coriolis_np = tuple([ (np.random.rand(nelem).astype(np.float64) - 0.5) * 0.1 for _ in range(4) ])\n",
    "\n",
    "    oodx = float(iicxn)\n",
    "    oody = float(iicyn)\n",
    "    x_periodic, y_periodic = True, True\n",
    "    x_wall, y_wall = False, False\n",
    "\n",
    "    # --- 1. Run Original Numba Version ---\n",
    "    print(\"Running Original Numba version...\")\n",
    "    try:\n",
    "        # Warm-up call\n",
    "        _ = lap2D_gather(p_np, igx, igy, iicxn, iicyn, hplusx_np, hplusy_np, hcenter_np, oodx, oody,\n",
    "                         x_periodic, y_periodic, x_wall, y_wall, diag_inv_np, coriolis_np)\n",
    "\n",
    "        start_time_orig = time.perf_counter()\n",
    "        for _ in range(num_trials):\n",
    "            result_orig = lap2D_gather(p_np, igx, igy, iicxn, iicyn, hplusx_np, hplusy_np, hcenter_np, oodx, oody,\n",
    "                                     x_periodic, y_periodic, x_wall, y_wall, diag_inv_np, coriolis_np)\n",
    "        end_time_orig = time.perf_counter()\n",
    "        time_orig_avg = (end_time_orig - start_time_orig) / num_trials\n",
    "        print(f\"Original average execution time: {time_orig_avg:.6f} seconds\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error running original version: {e}\")\n",
    "        time_orig_avg = float('inf')\n",
    "        result_orig = None\n",
    "\n",
    "\n",
    "    # --- 2. Run Refactored Numba Version ---\n",
    "    print(\"\\nRunning Refactored Numba version...\")\n",
    "    try:\n",
    "        # Optional output buffer for refactored version\n",
    "        out_buffer = np.zeros_like(p_np)\n",
    "        # Warm-up call\n",
    "        _ = lap2D_gather_refactored_numba(p_np, iicxn, iicyn, hplusx_np, hplusy_np, hcenter_np, oodx, oody,\n",
    "                                x_periodic, y_periodic, x_wall, y_wall, diag_inv_np, coriolis_np, out=out_buffer)\n",
    "\n",
    "        start_time_ref = time.perf_counter()\n",
    "        for _ in range(num_trials):\n",
    "            # Example using the output buffer\n",
    "            result_ref = lap2D_gather_refactored_numba(p_np, iicxn, iicyn, hplusx_np, hplusy_np, hcenter_np, oodx, oody,\n",
    "                                           x_periodic, y_periodic, x_wall, y_wall, diag_inv_np, coriolis_np, out=out_buffer)\n",
    "            # Or call without 'out' if preferred:\n",
    "            # result_ref = lap2D_gather_refactored_numba(p_np, iicxn, iicyn, hplusx_np, hplusy_np, hcenter_np, oodx, oody,\n",
    "            #                                x_periodic, y_periodic, x_wall, y_wall, diag_inv_np, coriolis_np)\n",
    "        end_time_ref = time.perf_counter()\n",
    "        time_ref_avg = (end_time_ref - start_time_ref) / num_trials\n",
    "        print(f\"Refactored average execution time: {time_ref_avg:.6f} seconds\")\n",
    "        # If using 'out', result_ref is the same buffer 'out_buffer'\n",
    "        if 'out_buffer' in locals() and result_ref is out_buffer:\n",
    "             result_ref = out_buffer.copy() # Copy if needed for comparison, as buffer is overwritten\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error running refactored version: {e}\")\n",
    "        time_ref_avg = float('inf')\n",
    "        result_ref = None\n",
    "\n",
    "    # --- 3. Compare Results ---\n",
    "    print(\"\\nComparing results...\")\n",
    "    if result_orig is not None and result_ref is not None:\n",
    "        try:\n",
    "            are_close = np.allclose(result_orig, result_ref, rtol=1e-9, atol=1e-12) # Use tighter tolerance\n",
    "            print(f\"Results are close: {are_close}\")\n",
    "            if not are_close:\n",
    "                diff = np.abs(result_orig - result_ref)\n",
    "                max_abs_diff = np.max(diff)\n",
    "                # Calculate relative difference carefully\n",
    "                # Add small epsilon to denominator to avoid division by zero/large rel diff for small numbers\n",
    "                denom = np.maximum(np.abs(result_orig), np.abs(result_ref)) + 1e-15\n",
    "                max_rel_diff = np.max(diff / denom)\n",
    "\n",
    "                print(f\"  Max absolute difference: {max_abs_diff:.2e}\")\n",
    "                print(f\"  Max relative difference: {max_rel_diff:.2e}\")\n",
    "                # Optionally print indices where differences occur\n",
    "                # diff_indices = np.where(~np.isclose(result_orig, result_ref, rtol=1e-9, atol=1e-12))[0]\n",
    "                # print(f\"  Indices with differences (first few): {diff_indices[:10]}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error during comparison: {e}\")\n",
    "            print(f\"  Original result shape: {result_orig.shape}, dtype: {result_orig.dtype}\")\n",
    "            print(f\"  Refactored result shape: {result_ref.shape}, dtype: {result_ref.dtype}\")\n",
    "    else:\n",
    "        print(\"Comparison skipped due to missing results.\")\n",
    "\n",
    "    print(\"-\" * 60)\n",
    "    return time_orig_avg, time_ref_avg\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # --- Configuration ---\n",
    "    grid_sizes = [(32, 32), (64, 64), (128, 128), (256, 256)] # Test different sizes\n",
    "    trials = 100 # Number of repetitions for timing\n",
    "\n",
    "    # --- Run Comparisons ---\n",
    "    results = {}\n",
    "    for size in grid_sizes:\n",
    "        iicxn, iicyn = size\n",
    "        try:\n",
    "            orig_t, ref_t = run_numba_comparison(iicxn, iicyn, num_trials=trials)\n",
    "            results[size] = {'original_time': orig_t, 'refactored_time': ref_t}\n",
    "        except Exception as e:\n",
    "            print(f\"\\n!!!!!! Error during comparison for size {size}: {e} !!!!!!\\n\")\n",
    "            results[size] = {'original_time': float('inf'), 'refactored_time': float('inf')}\n",
    "\n",
    "\n",
    "    # --- Print Summary ---\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Numba Comparison Summary (Average Times in seconds)\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"{'Grid Size':<12} | {'Original Time':<18} | {'Refactored Time':<18} | {'Speedup (Ref/Orig)':<18}\")\n",
    "    print(\"-\" * 60)\n",
    "    for size, times in results.items():\n",
    "        orig_t = times['original_time']\n",
    "        ref_t = times['refactored_time']\n",
    "        if orig_t == 0 or orig_t == float('inf') or ref_t == float('inf'):\n",
    "            speedup_str = \"N/A\"\n",
    "        else:\n",
    "            speedup = orig_t / ref_t\n",
    "            speedup_str = f\"{speedup:.2f}x\"\n",
    "        print(f\"{f'{size[0]}x{size[1]}':<12} | {orig_t:.6f}{'s':<12} | {ref_t:.6f}{'s':<12} | {speedup_str:<18}\")\n",
    "    print(\"=\" * 60)"
   ],
   "id": "b9c55b007f0931ad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Running comparison for grid size: 32 x 32\n",
      "Number of trials for timing: 100\n",
      "------------------------------------------------------------\n",
      "Running Original Numba version...\n",
      "Original average execution time: 0.000002 seconds\n",
      "\n",
      "Running Refactored Numba version...\n",
      "Refactored average execution time: 0.000001 seconds\n",
      "\n",
      "Comparing results...\n",
      "Results are close: True\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "Running comparison for grid size: 64 x 64\n",
      "Number of trials for timing: 100\n",
      "------------------------------------------------------------\n",
      "Running Original Numba version...\n",
      "Original average execution time: 0.000002 seconds\n",
      "\n",
      "Running Refactored Numba version...\n",
      "Refactored average execution time: 0.000002 seconds\n",
      "\n",
      "Comparing results...\n",
      "Results are close: True\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "Running comparison for grid size: 128 x 128\n",
      "Number of trials for timing: 100\n",
      "------------------------------------------------------------\n",
      "Running Original Numba version...\n",
      "Original average execution time: 0.000004 seconds\n",
      "\n",
      "Running Refactored Numba version...\n",
      "Refactored average execution time: 0.000003 seconds\n",
      "\n",
      "Comparing results...\n",
      "Results are close: True\n",
      "------------------------------------------------------------\n",
      "------------------------------------------------------------\n",
      "Running comparison for grid size: 256 x 256\n",
      "Number of trials for timing: 100\n",
      "------------------------------------------------------------\n",
      "Running Original Numba version...\n",
      "Original average execution time: 0.000011 seconds\n",
      "\n",
      "Running Refactored Numba version...\n",
      "Refactored average execution time: 0.000008 seconds\n",
      "\n",
      "Comparing results...\n",
      "Results are close: True\n",
      "------------------------------------------------------------\n",
      "\n",
      "============================================================\n",
      "Numba Comparison Summary (Average Times in seconds)\n",
      "============================================================\n",
      "Grid Size    | Original Time      | Refactored Time    | Speedup (Ref/Orig)\n",
      "------------------------------------------------------------\n",
      "32x32        | 0.000002s            | 0.000001s            | 1.17x             \n",
      "64x64        | 0.000002s            | 0.000002s            | 1.27x             \n",
      "128x128      | 0.000004s            | 0.000003s            | 1.10x             \n",
      "256x256      | 0.000011s            | 0.000008s            | 1.44x             \n",
      "============================================================\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T15:01:22.394632Z",
     "start_time": "2025-04-11T15:01:22.385312Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from typing import Tuple\n",
    "\n",
    "def gradient_2d_standalone(p_nodal: np.ndarray, dx: float, dy: float) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Calculates the cell-centered gradient of a 2D nodal scalar field.\n",
    "\n",
    "    Uses the difference-then-average scheme identified previously:\n",
    "    Dpx[i,j] = 0.5 * ( (p[i+1,j] - p[i,j])/dx + (p[i+1,j+1] - p[i,j+1])/dx )\n",
    "    Dpy[i,j] = 0.5 * ( (p[i,j+1] - p[i,j])/dy + (p[i+1,j+1] - p[i+1,j])/dy )\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    p_nodal : np.ndarray\n",
    "        The 2D nodal scalar field, shape (nx+1, ny+1).\n",
    "    dx : float\n",
    "        Grid spacing in the x-direction.\n",
    "    dy : float\n",
    "        Grid spacing in the y-direction.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[np.ndarray, np.ndarray]\n",
    "        The gradient components (Dpx_cell, Dpy_cell), both shape (nx, ny),\n",
    "        representing the gradient at cell centers.\n",
    "    \"\"\"\n",
    "    if p_nodal.ndim != 2:\n",
    "        raise ValueError(f\"Input p_nodal must be 2D, but got shape {p_nodal.shape}\")\n",
    "\n",
    "    # Calculate Dpx (gradient in x, centered in cells)\n",
    "    # Difference along x on bottom edges (shape nx, ny+1) then slice -> (nx, ny)\n",
    "    diff_x_bot = (p_nodal[1:, :-1] - p_nodal[:-1, :-1]) / dx\n",
    "    # Difference along x on top edges (shape nx, ny+1) then slice -> (nx, ny)\n",
    "    diff_x_top = (p_nodal[1:, 1:] - p_nodal[:-1, 1:]) / dx\n",
    "    Dpx_cell = 0.5 * (diff_x_bot + diff_x_top)\n",
    "\n",
    "    # Calculate Dpy (gradient in y, centered in cells)\n",
    "    # Difference along y on left edges (shape nx+1, ny) then slice -> (nx, ny)\n",
    "    diff_y_left = (p_nodal[:-1, 1:] - p_nodal[:-1, :-1]) / dy\n",
    "     # Difference along y on right edges (shape nx+1, ny) then slice -> (nx, ny)\n",
    "    diff_y_right = (p_nodal[1:, 1:] - p_nodal[1:, :-1]) / dy\n",
    "    Dpy_cell = 0.5 * (diff_y_left + diff_y_right)\n",
    "\n",
    "    return Dpx_cell, Dpy_cell\n",
    "\n",
    "\n",
    "def derivative_2d_standalone(var_cell: np.ndarray, axis: int, dx: float, dy: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calculates the nodal derivative of a 2D cell-centered variable.\n",
    "\n",
    "    Computes differences between adjacent cell centers along 'axis' (giving\n",
    "    values on intermediate faces), then averages these face values along the\n",
    "    other axis to get the result at interior nodes.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    var_cell : np.ndarray\n",
    "        The 2D cell-centered variable, shape (nx, ny).\n",
    "    axis : int\n",
    "        Axis along which to compute the derivative (0 for x, 1 for y).\n",
    "    dx : float\n",
    "        Grid spacing in the x-direction.\n",
    "    dy : float\n",
    "        Grid spacing in the y-direction.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        The nodal derivative, defined on interior nodes. Shape (nx-1, ny-1).\n",
    "    \"\"\"\n",
    "    if var_cell.ndim != 2:\n",
    "        raise ValueError(f\"Input var_cell must be 2D, but got shape {var_cell.shape}\")\n",
    "    if axis not in [0, 1]:\n",
    "         raise ValueError(f\"Axis must be 0 or 1, but got {axis}\")\n",
    "\n",
    "    # Determine grid spacing for the derivative axis\n",
    "    ds = dx if axis == 0 else dy\n",
    "\n",
    "    # Compute the primary difference between cell centers along the specified axis.\n",
    "    # This gives values located on the faces between the differenced cells.\n",
    "    # If axis=0, shape is (nx-1, ny). If axis=1, shape is (nx, ny-1).\n",
    "    diff_on_faces = np.diff(var_cell, axis=axis) / ds\n",
    "\n",
    "    # Average these face values along the *other* axis to get nodal values.\n",
    "    if axis == 0:\n",
    "        # diff_on_faces has shape (nx-1, ny). Average along axis 1 (y-direction).\n",
    "        # Average vertical faces values horizontally to get value at node.\n",
    "        result_node = 0.5 * (diff_on_faces[:, :-1] + diff_on_faces[:, 1:])\n",
    "    else: # axis == 1\n",
    "        # diff_on_faces has shape (nx, ny-1). Average along axis 0 (x-direction).\n",
    "        # Average horizontal faces values vertically to get value at node.\n",
    "        result_node = 0.5 * (diff_on_faces[:-1, :] + diff_on_faces[1:, :])\n",
    "\n",
    "    # The result is shape (nx-1, ny-1), located at interior nodes.\n",
    "    return result_node\n",
    "\n",
    "# --- Example Usage ---\n",
    "if __name__ == '__main__':\n",
    "    nx, ny = 5, 4  # Number of cells\n",
    "    dx, dy = 0.2, 0.25\n",
    "\n",
    "    # Create a sample nodal field (nx+1, ny+1)\n",
    "    x_nodes = np.linspace(0, nx * dx, nx + 1)\n",
    "    y_nodes = np.linspace(0, ny * dy, ny + 1)\n",
    "    Xn, Yn = np.meshgrid(x_nodes, y_nodes, indexing='ij')\n",
    "    p_nodal_test = np.sin(np.pi * Xn) * np.cos(np.pi * Yn / 2.0)\n",
    "\n",
    "    print(\"--- Testing gradient_2d_standalone ---\")\n",
    "    Dpx, Dpy = gradient_2d_standalone(p_nodal_test, dx, dy)\n",
    "    print(f\"Input p_nodal shape: {p_nodal_test.shape}\")\n",
    "    print(f\"Output Dpx shape: {Dpx.shape}\") # Should be (nx, ny) = (5, 4)\n",
    "    print(f\"Output Dpy shape: {Dpy.shape}\") # Should be (nx, ny) = (5, 4)\n",
    "    # print(\"Dpx:\\n\", Dpx)\n",
    "    # print(\"Dpy:\\n\", Dpy)\n",
    "\n",
    "    print(\"\\n--- Testing derivative_2d_standalone ---\")\n",
    "    # Use Dpx as a sample cell-centered field\n",
    "    dDpx_dx = derivative_2d_standalone(Dpx, axis=0, dx=dx, dy=dy)\n",
    "    dDpx_dy = derivative_2d_standalone(Dpx, axis=1, dx=dx, dy=dy)\n",
    "    print(f\"Input Dpx shape: {Dpx.shape}\")\n",
    "    print(f\"Output d(Dpx)/dx shape: {dDpx_dx.shape}\") # Should be (nx-1, ny-1) = (4, 3)\n",
    "    print(f\"Output d(Dpx)/dy shape: {dDpx_dy.shape}\") # Should be (nx-1, ny-1) = (4, 3)\n",
    "    # print(\"d(Dpx)/dx:\\n\", dDpx_dx)\n",
    "    # print(\"d(Dpx)/dy:\\n\", dDpx_dy)\n",
    "\n",
    "    # --- Example: Construct a simple Laplacian (Div(Grad(p))) ---\n",
    "    # This ignores coefficients and boundary complexities for illustration\n",
    "    Dpx_c, Dpy_c = gradient_2d_standalone(p_nodal_test, dx, dy)\n",
    "    dDpx_dx_n = derivative_2d_standalone(Dpx_c, axis=0, dx=dx, dy=dy)\n",
    "    dDpy_dy_n = derivative_2d_standalone(Dpy_c, axis=1, dx=dx, dy=dy)\n",
    "    laplacian_p_nodes_interior = dDpx_dx_n + dDpy_dy_n\n",
    "    print(\"\\n--- Simple Laplacian (Interior Nodes) ---\")\n",
    "    print(f\"Laplacian(p) shape: {laplacian_p_nodes_interior.shape}\") # Should be (nx-1, ny-1) = (4, 3)\n",
    "    # print(\"Laplacian(p):\\n\", laplacian_p_nodes_interior)"
   ],
   "id": "e7fb21f4d21ac1b3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Testing gradient_2d_standalone ---\n",
      "Input p_nodal shape: (6, 5)\n",
      "Output Dpx shape: (5, 4)\n",
      "Output Dpy shape: (5, 4)\n",
      "\n",
      "--- Testing derivative_2d_standalone ---\n",
      "Input Dpx shape: (5, 4)\n",
      "Output d(Dpx)/dx shape: (4, 3)\n",
      "Output d(Dpx)/dy shape: (4, 3)\n",
      "\n",
      "--- Simple Laplacian (Interior Nodes) ---\n",
      "Laplacian(p) shape: (4, 3)\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T15:02:05.163020Z",
     "start_time": "2025-04-11T15:02:05.157120Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "# Assume gradient and derivative functions exist and work as described above\n",
    "# from your_module import gradient, derivative\n",
    "\n",
    "def laplacian_naive_composed(\n",
    "    p_node_full: np.ndarray,  # Nodal p including boundaries, shape (nx+1, ny+1)\n",
    "    nx: int,                  # Number of cells/internal nodes in x\n",
    "    ny: int,                  # Number of cells/internal nodes in y\n",
    "    # --- Coefficients (Assume correctly located) ---\n",
    "    hplusx_cell: np.ndarray,  # Shape (nx, ny)\n",
    "    hplusy_cell: np.ndarray,  # Shape (nx, ny)\n",
    "    hcenter_node_int: np.ndarray,# Shape (nx, ny) - On internal nodes\n",
    "    diag_inv_node_int: np.ndarray, # Shape (nx, ny) - On internal nodes\n",
    "    coriolis_cell: tuple,     # Tuple (cyy, cxx, cyx, cxy), each shape (nx, ny)\n",
    "    # --- Grid Info ---\n",
    "    dxyz: tuple,              # (dx, dy, dz) - only dx, dy used here\n",
    "    ndim: int = 2\n",
    "    # --- Boundary Flags (Assumed handled by gradient/derivative internals) ---\n",
    "    # x_periodic, y_periodic, x_wall, y_wall\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Naive implementation of Laplacian operator by composing gradient and derivative.\n",
    "\n",
    "    Computes Result  diag_inv * [ Div( C * Grad(p) ) + hcenter * p ]\n",
    "\n",
    "    WARNING: This is for structural understanding. It is NOT performant\n",
    "             due to intermediate arrays and may differ numerically from\n",
    "             a fused stencil implementation like lap2D_gather.\n",
    "             Assumes gradient/derivative handle boundaries correctly.\n",
    "    \"\"\"\n",
    "    if ndim != 2:\n",
    "        raise NotImplementedError(\"This naive version is only for 2D\")\n",
    "\n",
    "    dx, dy = dxyz[0], dxyz[1]\n",
    "    cyy_cell, cxx_cell, cyx_cell, cxy_cell = coriolis_cell\n",
    "\n",
    "    # --- Step 1: Gradient (Node -> Cell Center) ---\n",
    "    # Assumes gradient function handles boundaries based on p_node_full size/padding\n",
    "    Dpx_cell, Dpy_cell, _ = gradient_2d_standalone(p_node_full, ndim, dxyz) # Output shape (nx, ny)\n",
    "\n",
    "    # --- Step 2: Apply Coefficients to get Cell-Centered Flux ---\n",
    "    # Fx = cxx*(hpx*Dpx) + cxy*(hpy*Dpy)\n",
    "    # Fy = cyx*(hpx*Dpx) + cyy*(hpy*Dpy)\n",
    "    term_x = hplusx_cell * Dpx_cell\n",
    "    term_y = hplusy_cell * Dpy_cell\n",
    "\n",
    "    Fx_cell = cxx_cell * term_x + cxy_cell * term_y\n",
    "    Fy_cell = cyx_cell * term_x + cyy_cell * term_y\n",
    "    # Fx_cell, Fy_cell have shape (nx, ny)\n",
    "\n",
    "    # --- Step 3: Divergence (Cell Center -> Node Center) ---\n",
    "    # Assumes derivative returns result on internal nodes, shape (nx, ny)\n",
    "    # Assumes derivative function handles boundaries correctly\n",
    "    div_Fx_node = derivative_2d_standalone(Fx_cell, axis=0, ndim=ndim, dxyz=dxyz)\n",
    "    div_Fy_node = derivative_2d_standalone(Fy_cell, axis=1, ndim=ndim, dxyz=dxyz)\n",
    "    # div_Fx_node, div_Fy_node assumed shape (nx, ny)\n",
    "\n",
    "    divergence_node = div_Fx_node + div_Fy_node # Shape (nx, ny)\n",
    "\n",
    "    # --- Step 4: Add Center Term & Apply Preconditioner ---\n",
    "    # Need p on the same internal nodes as the divergence result\n",
    "    # Extract internal p values from the full nodal array\n",
    "    # Assuming internal nodes correspond to indices 1:-1 or 0:nx\n",
    "    # Let's assume indices 0:nx, 0:ny match the DoF count nx*ny\n",
    "    p_node_int = p_node_full[0:nx, 0:ny] # Example slicing - NEEDS VERIFICATION\n",
    "\n",
    "    lap_val_node = divergence_node + hcenter_node_int * p_node_int\n",
    "    result_node_int = lap_val_node * diag_inv_node_int # Shape (nx, ny)\n",
    "\n",
    "    # --- Step 5: Flatten result ---\n",
    "    # Return a 1D array consistent with solvers / lap2D_gather output\n",
    "    return result_node_int.flatten()"
   ],
   "id": "c73b2ed3cc804e50",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T15:03:56.975297Z",
     "start_time": "2025-04-11T15:03:56.891058Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def compare_laplacian_results(iicxn, iicyn):\n",
    "    \"\"\"\n",
    "    Compares the results of the fused Numba and naive composed implementations.\n",
    "    \"\"\"\n",
    "    print(\"-\" * 60)\n",
    "    print(f\"Comparing results for grid size: {iicxn} x {iicyn}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    nx, ny = iicxn, iicyn # Internal node counts often match cell counts\n",
    "    ngnc = nx * ny      # Number of internal grid nodes / DoFs\n",
    "\n",
    "    # --- Generate Consistent Random Test Data (CPU) ---\n",
    "    np.random.seed(42)\n",
    "    # Nodal array including boundary nodes (size (nx+1) x (ny+1))\n",
    "    p_nodal_full = np.random.rand(nx + 1, ny + 1).astype(np.float64)\n",
    "    # Flattened internal node vector for fused version (size ngnc)\n",
    "    # Assuming internal nodes are indexed [1:-1, 1:-1] in the full nodal array\n",
    "    # Or adjust if internal nodes correspond to [0:nx, 0:ny]\n",
    "    # Let's assume the DoFs correspond to nodes 0..nx-1, 0..ny-1 for simplicity\n",
    "    # Need to be consistent with how lap2D_gather_fused expects its input\n",
    "    # If lap2D_gather_fused works on p[0:nx, 0:ny] flattened:\n",
    "    p_internal_flat = p_nodal_full[0:nx, 0:ny].flatten()\n",
    "\n",
    "    # Coefficients\n",
    "    # Cell-centered coeffs for naive version (shape (nx, ny))\n",
    "    hplusx_cell = np.random.rand(nx, ny).astype(np.float64) + 0.1\n",
    "    hplusy_cell = np.random.rand(nx, ny).astype(np.float64) + 0.1\n",
    "    coriolis_cell = tuple([(np.random.rand(nx, ny) - 0.5) * 0.1 for _ in range(4)])\n",
    "\n",
    "    # Nodal coeffs on internal nodes for naive version (shape (nx, ny))\n",
    "    hcenter_node_int = np.random.rand(nx, ny).astype(np.float64) * 5.0 + 1.0\n",
    "    diag_inv_node_int = (1.0 / hcenter_node_int).astype(np.float64)\n",
    "\n",
    "    # Coeffs for fused version (might be element or node based, need consistency)\n",
    "    # Assuming fused version needs element-based (like cells), shape (nx, ny)\n",
    "    hplusx_fused = hplusx_cell\n",
    "    hplusy_fused = hplusy_cell\n",
    "    # Assuming fused version needs nodal center/diag_inv flattened (size ngnc)\n",
    "    hcenter_fused = hcenter_node_int.flatten()\n",
    "    diag_inv_fused = diag_inv_node_int.flatten()\n",
    "    # Assuming fused version needs coriolis flattened or passed as tuple of cell arrays\n",
    "    coriolis_fused = tuple(c.flatten() for c in coriolis_cell) # Example: Flatten if needed\n",
    "    # *** Crucially, ensure the coefficients passed to both versions represent\n",
    "    # *** the SAME physical quantities at the SAME logical locations.\n",
    "\n",
    "    # Grid spacing and boundary conditions\n",
    "    dx = 1.0 / nx\n",
    "    dy = 1.0 / ny\n",
    "    oodx = 1.0 / dx\n",
    "    oody = 1.0 / dy\n",
    "    dxyz = (dx, dy, 0.0)\n",
    "    x_periodic, y_periodic = False, False # Test with walls first maybe\n",
    "    x_wall, y_wall = True, True\n",
    "\n",
    "    # --- 1. Run Fused Numba Version ---\n",
    "    print(\"Running Fused Numba version (lap2D_gather)...\")\n",
    "    try:\n",
    "        # Note: lap2D_gather needs iicxn=nx, iicyn=ny for internal node counts\n",
    "        result_fused = lap2D_gather(\n",
    "            p_internal_flat, nx, ny,\n",
    "            hplusx_fused, hplusy_fused, hcenter_fused, oodx, oody,\n",
    "            x_periodic, y_periodic, x_wall, y_wall, diag_inv_fused, coriolis_fused\n",
    "        )\n",
    "        print(\"Fused version ran.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error running fused version: {e}\")\n",
    "        result_fused = None\n",
    "\n",
    "\n",
    "    # --- 2. Run Naive Composed Version ---\n",
    "    print(\"\\nRunning Naive Composed version (laplacian_naive_composed)...\")\n",
    "    try:\n",
    "        # Pass full nodal p and cell/internal node coefficients\n",
    "        result_composed = laplacian_naive_composed(\n",
    "            p_nodal_full, nx, ny,\n",
    "            hplusx_cell, hplusy_cell, hcenter_node_int, diag_inv_node_int,\n",
    "            coriolis_cell, dxyz, ndim=2\n",
    "        )\n",
    "        print(\"Composed version ran.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error running composed version: {e}\")\n",
    "        result_composed = None\n",
    "\n",
    "\n",
    "    # --- 3. Compare Results ---\n",
    "    print(\"\\nComparing results...\")\n",
    "    if result_fused is not None and result_composed is not None:\n",
    "        if result_fused.shape != result_composed.shape:\n",
    "            print(\" !!! Result shapes differ !!!\")\n",
    "            print(f\"  Fused shape:    {result_fused.shape}\")\n",
    "            print(f\"  Composed shape: {result_composed.shape}\")\n",
    "            print(\" Cannot compare results.\")\n",
    "        else:\n",
    "            try:\n",
    "                # Use a relatively loose tolerance initially, as numerical paths differ\n",
    "                are_close = np.allclose(result_fused, result_composed, rtol=1e-5, atol=1e-7)\n",
    "                print(f\"Results are close (rtol=1e-5, atol=1e-7): {are_close}\")\n",
    "                if not are_close:\n",
    "                    diff = np.abs(result_fused - result_composed)\n",
    "                    max_abs_diff = np.max(diff)\n",
    "                    # Add small epsilon to denominator to avoid division by zero/large rel diff for small numbers\n",
    "                    denom = np.maximum(np.abs(result_fused), np.abs(result_composed)) + 1e-15\n",
    "                    max_rel_diff = np.max(diff / denom)\n",
    "\n",
    "                    print(f\"  Max absolute difference: {max_abs_diff:.2e}\")\n",
    "                    print(f\"  Max relative difference: {max_rel_diff:.2e}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error during comparison: {e}\")\n",
    "                print(f\"  Fused result dtype:    {result_fused.dtype}\")\n",
    "                print(f\"  Composed result dtype: {result_composed.dtype}\")\n",
    "    else:\n",
    "        print(\"Comparison skipped due to missing results or errors during execution.\")\n",
    "\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # --- Configuration ---\n",
    "    # Use a small grid size for initial comparison\n",
    "    grid_size_compare = (16, 16)\n",
    "\n",
    "    # --- Run Comparison ---\n",
    "    compare_laplacian_results(grid_size_compare[0], grid_size_compare[1])"
   ],
   "id": "e733430d918c3082",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "Comparing results for grid size: 16 x 16\n",
      "------------------------------------------------------------\n",
      "Running Fused Numba version (lap2D_gather)...\n",
      "Fused version ran.\n",
      "\n",
      "Running Naive Composed version (laplacian_naive_composed)...\n",
      "Error running composed version: operands could not be broadcast together with shapes (16,16) (3,) \n",
      "\n",
      "Comparing results...\n",
      "Comparison skipped due to missing results or errors during execution.\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 35
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
