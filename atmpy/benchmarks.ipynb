{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T14:15:36.219272Z",
     "start_time": "2025-04-15T14:15:36.176478Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import numba as nb\n",
    "from typing import Tuple\n",
    "\n",
    "# ==========================================================================\n",
    "# 1. Standalone Building Blocks for the New Laplacian Method\n",
    "# ==========================================================================\n",
    "\n",
    "def calculate_pTheta_placeholder(nx: int, ny: int) -> np.ndarray:\n",
    "    \"\"\"Placeholder: Calculates coefficient corresponding to hplus (cell-centered).\"\"\"\n",
    "    # In reality, this depends on thermodynamic variables (rho, rhoY, GammaInv, Y)\n",
    "    # For testing, use random positive values.\n",
    "    print(\"INFO: Using placeholder for pTheta coefficient.\")\n",
    "    return np.random.rand(nx, ny) + 0.5 # Shape (nx, ny) - cell centered\n",
    "\n",
    "def calculate_helmholtz_coeff_placeholder(nx: int, ny: int) -> np.ndarray:\n",
    "    \"\"\"Placeholder: Calculates Helmholtz coefficient (nodal).\"\"\"\n",
    "    # In reality, depends on compressibility, rhoY, etc.\n",
    "    # For testing, use random values.\n",
    "    print(\"INFO: Using placeholder for Helmholtz coefficient.\")\n",
    "    # Note: C code calculates this via scattering, resulting in nodal values.\n",
    "    return np.random.rand(nx + 1, ny + 1) * 0.1 # Shape (nx+1, ny+1) - nodal\n",
    "\n",
    "@nb.jit(nopython=True, nogil=True, cache=True)\n",
    "def gradient_nodal_to_cell(p_nodal: np.ndarray, dx: float, dy: float, nx: int, ny: int) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Computes gradient at cell centers from nodal values.\n",
    "    Equivalent to the C code's Dpx, Dpy calculation inside\n",
    "    correction_increments_nodes and the user's original Python gradient.\n",
    "    Assumes p_nodal includes boundary nodes.\n",
    "    \"\"\"\n",
    "    dpdx = np.zeros((nx, ny))\n",
    "    dpdy = np.zeros((nx, ny))\n",
    "\n",
    "    # This implements the 0.25 * (diff + diff + diff + diff) averaging scheme\n",
    "    # For dpdx at cell (i, j), uses nodes (i,j), (i+1,j), (i,j+1), (i+1,j+1)\n",
    "    for j in range(ny):\n",
    "        for i in range(nx):\n",
    "            n00 = p_nodal[i, j]\n",
    "            n10 = p_nodal[i+1, j]\n",
    "            n01 = p_nodal[i, j+1]\n",
    "            n11 = p_nodal[i+1, j+1]\n",
    "            dpdx[i, j] = 0.25 * (n10 - n00 + n11 - n01 + n10 - n00 + n11 - n01) / dx # Simplified from 3D version, double check averaging logic\n",
    "            dpdy[i, j] = 0.25 * (n01 - n00 + n11 - n10 + n01 - n00 + n11 - n10) / dy # Simplified from 3D version, double check averaging logic\n",
    "\n",
    "            # Let's use the exact 2D logic from the user's original gradient function if available\n",
    "            # Or derive from the 3D C code: Dpx = 0.25 * oodx * (p[n001] - p[n000] + p[n011] - p[n010] + p[n101] - p[n100] + p[n111] - p[n110]);\n",
    "            # In 2D: n00=p[i,j], n10=p[i+1,j], n01=p[i,j+1], n11=p[i+1,j+1]\n",
    "            # Dpx = 0.5 * oodx * (p[n10] - p[n00] + p[n11] - p[n01]) equivalent to signs (-1, -1, +1, +1)\n",
    "            # Dpy = 0.5 * oody * (p[n01] - p[n00] + p[n11] - p[n10]) equivalent to signs (-1, +1, -1, +1)\n",
    "            dpdx[i, j] = 0.5 * (n10 - n00 + n11 - n01) / dx\n",
    "            dpdy[i, j] = 0.5 * (n01 - n00 + n11 - n10) / dy\n",
    "\n",
    "    return dpdx, dpdy\n",
    "\n",
    "#@nb.jit(nopython=True, nogil=True, cache=True) # Numba might struggle with dicts/complex args easily\n",
    "def apply_coriolis_transform_placeholder(u: np.ndarray, v: np.ndarray, w: np.ndarray, dt: float, coriolis_params: Tuple[float, float, float]):\n",
    "    \"\"\"\n",
    "    Placeholder for the T_inverse transformation (Coriolis, buoyancy).\n",
    "    Modifies u, v, w IN-PLACE. For testing, set effect to zero.\n",
    "    \"\"\"\n",
    "    print(\"INFO: Using placeholder (identity) for Coriolis transform.\")\n",
    "    # To test non-identity, uncomment below:\n",
    "    # u *= (1.0 + dt * 0.1)\n",
    "    # v *= (1.0 - dt * 0.1)\n",
    "    pass # No operation for identity transform\n",
    "\n",
    "#@nb.jit(nopython=True, nogil=True, cache=True) # Numba might struggle with dicts/complex args easily\n",
    "def calculate_correction_increments_nodes(p_nodal: np.ndarray, pTheta: np.ndarray, dx: float, dy: float, dt: float, nx: int, ny: int, coriolis_params: Tuple[float, float, float]) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Calculates and returns the intermediate transformed flux increments.\n",
    "    Mirrors C's correction_increments_nodes.\n",
    "    \"\"\"\n",
    "    # Calculate gradient (nodal -> cell)\n",
    "    dpdx, dpdy = gradient_nodal_to_cell(p_nodal, dx, dy, nx, ny)\n",
    "\n",
    "    # Calculate initial flux increment (cell-centered)\n",
    "    u = -dt * pTheta * dpdx\n",
    "    v = -dt * pTheta * dpdy\n",
    "    w = np.zeros_like(u) # 2D placeholder\n",
    "\n",
    "    # Apply Coriolis/Buoyancy transform (T_inv) in-place\n",
    "    apply_coriolis_transform_placeholder(u, v, w, dt, coriolis_params)\n",
    "\n",
    "    # u, v, w now contain the transformed increments\n",
    "    return u, v, w\n",
    "\n",
    "@nb.jit(nopython=True, nogil=True, cache=True)\n",
    "def divergence_cell_to_node(u_cell: np.ndarray, v_cell: np.ndarray, w_cell: np.ndarray,\n",
    "                            dx: float, dy: float, dz: float, # dz needed for scaling even in 2D if C code uses it\n",
    "                            nx: int, ny: int,\n",
    "                            Xbot: np.ndarray, Xtop: np.ndarray, # Boundary factors\n",
    "                            is_x_periodic: bool, is_y_periodic: bool) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calculates divergence at nodes from cell-centered vectors using scattering.\n",
    "    Mirrors C's divergence_nodes_Pv. Output is on inner nodes (nx, ny).\n",
    "    \"\"\"\n",
    "    div_nodal = np.zeros((nx + 1, ny + 1)) # Nodal grid, including boundaries\n",
    "    oodx = 1.0 / dx\n",
    "    oody = 1.0 / dy\n",
    "    oodz = 1.0 / dz # Use non-zero dz=1.0 for 2D if C code did\n",
    "\n",
    "    # Loop over cells (i_cell, j_cell) from 0 to nx-1, 0 to ny-1\n",
    "    for j_cell in range(ny):\n",
    "        for i_cell in range(nx):\n",
    "            ne = i_cell + j_cell * nx # Placeholder index if needed, C code uses 2D indices\n",
    "\n",
    "            # Get cell-centered velocity components\n",
    "            u_c = u_cell[i_cell, j_cell]\n",
    "            v_c = v_cell[i_cell, j_cell]\n",
    "            w_c = w_cell[i_cell, j_cell] # Zero for 2D\n",
    "\n",
    "            # Calculate flux terms to scatter\n",
    "            tmpfx = 0.25 * oodx * u_c\n",
    "            tmpfy = 0.25 * oody * v_c\n",
    "            tmpfz = 0.25 * oodz * w_c # Scales by oodz even if w_c is 0\n",
    "\n",
    "            # Get boundary scaling factors (assuming Xbot/Xtop are 1D arrays of size nx)\n",
    "            isbot = (j_cell == 0)\n",
    "            istop = (j_cell == ny - 1)\n",
    "            # Ensure correct indexing for Xbot/Xtop (size nx)\n",
    "            xb = Xbot[i_cell] if isbot else 1.0\n",
    "            xt = Xtop[i_cell] if istop else 1.0\n",
    "            # C code version DIV_HOR_SCALED_TO_VERTICAL_BDRY:\n",
    "            # Multiplies tmpfx, tmpfz by Xbot/Xtop, adds tmpfy separately\n",
    "\n",
    "\n",
    "            # Node indices (bottom-left node of cell is (i_cell, j_cell))\n",
    "            nn00 = (i_cell)   + (j_cell)   * (nx + 1) # Node (i, j)\n",
    "            nn10 = (i_cell+1) + (j_cell)   * (nx + 1) # Node (i+1, j)\n",
    "            nn01 = (i_cell)   + (j_cell+1) * (nx + 1) # Node (i, j+1)\n",
    "            nn11 = (i_cell+1) + (j_cell+1) * (nx + 1) # Node (i+1, j+1)\n",
    "\n",
    "            # Scattering based on C code divergence_nodes_Pv (using Xbot/Xtop scaling)\n",
    "            # Note: C code uses +/- signs differently depending on DIV_HOR_SCALED_TO_VERTICAL_BDRY\n",
    "            # Let's use the one shown in divergence_nodes_Pv\n",
    "            # div[nn000] += + tmpfy + (+ tmpfx + tmpfz) * Xbot; -> Node (i, j) gets from cell (i, j)\n",
    "            # div[nn100] += + tmpfy + (- tmpfx + tmpfz) * Xbot; -> Node (i+1, j) gets from cell (i, j)\n",
    "            # div[nn010] += - tmpfy + (+ tmpfx + tmpfz) * Xtop; -> Node (i, j+1) gets from cell (i, j)\n",
    "            # div[nn110] += - tmpfy + (- tmpfx + tmpfz) * Xtop; -> Node (i+1, j+1) gets from cell (i, j)\n",
    "            # And contributions from cells (i-1, j), (i, j-1), (i-1, j-1) need adding up\n",
    "\n",
    "            # Reshape div_nodal temporarily for easy 2D indexing\n",
    "            div_nodal_2d = div_nodal.reshape((ny + 1, nx + 1))\n",
    "\n",
    "            # Scatter from cell (i_cell, j_cell) to its four surrounding nodes\n",
    "            div_nodal_2d[j_cell,   i_cell]   += +tmpfy + (+tmpfx + tmpfz) * xb # nn00 from cell (i_cell, j_cell)\n",
    "            div_nodal_2d[j_cell,   i_cell+1] += +tmpfy + (-tmpfx + tmpfz) * xb # nn10 from cell (i_cell, j_cell)\n",
    "            div_nodal_2d[j_cell+1, i_cell]   += -tmpfy + (+tmpfx + tmpfz) * xt # nn01 from cell (i_cell, j_cell)\n",
    "            div_nodal_2d[j_cell+1, i_cell+1] += -tmpfy + (-tmpfx + tmpfz) * xt # nn11 from cell (i_cell, j_cell)\n",
    "\n",
    "\n",
    "    # Extract the inner nodes (nx, ny)\n",
    "    # The nodal indices corresponding to inner nodes are [1:nx+1, 1:ny+1]\n",
    "    # However, the C code loops imply the output size is nx*ny\n",
    "    # The scattering accumulates at nodes (0..nx, 0..ny).\n",
    "    # Which nodes correspond to the 'inner' result? Often node (i,j) result corresponds\n",
    "    # to indices (i-igx, j-igy). Let's assume inner nodes are [igx:icx-igx, igy:icy-igy]\n",
    "    # For simplicity, let igx=igy=1. Inner nodes are [1:nx+1, 1:ny+1].\n",
    "    div_inner = div_nodal.reshape((ny + 1, nx + 1))[1:ny+1, 1:nx+1]\n",
    "\n",
    "    return div_inner # Shape (ny, nx) -> transpose if needed\n",
    "\n",
    "#@nb.jit(nopython=True, nogil=True, cache=True) # Numba might struggle with dicts/complex args easily\n",
    "def calculate_new_laplacian_action(p_nodal: np.ndarray, pTheta: np.ndarray, helmholtz_coeff_nodal: np.ndarray,\n",
    "                                   dx: float, dy: float, dz: float, dt: float, nx: int, ny: int,\n",
    "                                   coriolis_params: Tuple[float, float, float],\n",
    "                                   Xbot: np.ndarray, Xtop: np.ndarray,\n",
    "                                   is_x_periodic: bool, is_y_periodic: bool) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calculates the action of the Laplacian operator L(p) using the new structure.\n",
    "    Mirrors C code logic: increments -> divergence -> Helmholtz.\n",
    "    \"\"\"\n",
    "    # Pad p_nodal for gradient calculation if periodic\n",
    "    # Simple 1-layer padding sufficient for first-order differences\n",
    "    p_padded = np.pad(p_nodal, ((1,1),(1,1)), mode='wrap' if is_x_periodic and is_y_periodic else 'constant')\n",
    "    if is_x_periodic:\n",
    "        p_padded[:, 0] = p_padded[:, -2]\n",
    "        p_padded[:, -1] = p_padded[:, 1]\n",
    "    if is_y_periodic:\n",
    "        p_padded[0, :] = p_padded[-2, :]\n",
    "        p_padded[-1, :] = p_padded[1, :]\n",
    "        # Corners if both periodic\n",
    "        if is_x_periodic:\n",
    "             p_padded[0, 0] = p_padded[-2, -2]\n",
    "             p_padded[0, -1] = p_padded[-2, 1]\n",
    "             p_padded[-1, 0] = p_padded[1, -2]\n",
    "             p_padded[-1, -1] = p_padded[1, 1]\n",
    "\n",
    "    # Calculate Transformed Flux Increments (Cell Centered) using padded pressure\n",
    "    # Note: Need to adjust nx,ny input to gradient if p_padded is used directly\n",
    "    # Or, implement gradient to handle padding internally. Let's adjust nx, ny.\n",
    "    # The core calculation area for gradient is still nx x ny cells.\n",
    "    # It reads from p_padded which has size (nx+3, ny+3) effectively? No, pad is (nx+1)+2 = nx+3.\n",
    "    # Let's stick to passing p_nodal and handle boundaries inside gradient (more complex)\n",
    "    # Easier: Pass p_padded, but gradient needs modification or careful indexing.\n",
    "\n",
    "    # Let's assume gradient works on (nx+1, ny+1) input and needs padding handled outside.\n",
    "    # We already padded p_nodal. The gradient function as written accesses p_nodal[i+1, j+1] max.\n",
    "    # So passing the original p_nodal (nx+1, ny+1) to gradient should be fine if it handles boundary indexing.\n",
    "    # Revisit gradient_nodal_to_cell - it assumes input is (nx+1, ny+1)\n",
    "    # Let's assume p_nodal already has ghost cells filled appropriately.\n",
    "    u_incr, v_incr, w_incr = calculate_correction_increments_nodes(\n",
    "        p_nodal, pTheta, dx, dy, dt, nx, ny, coriolis_params\n",
    "    )\n",
    "\n",
    "    # Calculate Divergence of Increments (Nodal Inner)\n",
    "    divergence_term = divergence_cell_to_node(\n",
    "        u_incr, v_incr, w_incr, dx, dy, dz, nx, ny, Xbot, Xtop, is_x_periodic, is_y_periodic\n",
    "    ).T\n",
    "\n",
    "    # Add Helmholtz Term\n",
    "    p_inner = p_nodal[1:nx+1, 1:ny+1]\n",
    "    helmholtz_coeff_inner = helmholtz_coeff_nodal[1:nx+1, 1:ny+1]\n",
    "\n",
    "    if divergence_term.shape != helmholtz_coeff_inner.shape or divergence_term.shape != p_inner.shape:\n",
    "        raise ValueError(f\"Shape mismatch for Helmholtz term: Div={divergence_term.shape}, Coeff={helmholtz_coeff_inner.shape}, P={p_inner.shape}\")\n",
    "\n",
    "    helmholtz_term_result = helmholtz_coeff_inner * p_inner\n",
    "\n",
    "    # Combine\n",
    "    lap_result = divergence_term + helmholtz_term_result # Shape (nx, ny)\n",
    "\n",
    "    # Preconditioning/Scaling (diag_inv) is omitted here\n",
    "    return lap_result\n",
    "\n",
    "# ==========================================================================\n",
    "# 2. lap2D_gather Function (Copied from user prompt)\n",
    "# ==========================================================================\n",
    "\n",
    "@nb.jit(nopython=True, nogil=False, cache=True)\n",
    "def lap2D_gather(p, igx, igy, iicxn, iicyn, hplusx, hplusy, hcenter, oodx, oody, x_periodic, y_periodic, x_wall, y_wall,\n",
    "                 diag_inv, coriolis):\n",
    "    ngnc = (iicxn) * (iicyn)\n",
    "    lap = np.zeros((ngnc))\n",
    "    cnt_x = 0\n",
    "    cnt_y = 0\n",
    "\n",
    "    nine_pt = 0.25 * (2.0) * 1.0\n",
    "    cyy, cxx, cyx, cxy = coriolis\n",
    "    oodx2 = 0.5 * oodx ** 2\n",
    "    oody2 = 0.5 * oody ** 2\n",
    "\n",
    "    for idx in range(iicxn * iicyn):\n",
    "        ne_topleft = idx - iicxn - 1\n",
    "        ne_topright = idx - iicxn\n",
    "        ne_botleft = idx - 1\n",
    "        ne_botright = idx\n",
    "\n",
    "        # get indices of the 9pt stencil\n",
    "        topleft_idx = idx - iicxn - 1\n",
    "        midleft_idx = idx - 1\n",
    "        botleft_idx = idx + iicxn - 1\n",
    "\n",
    "        topmid_idx = idx - iicxn\n",
    "        midmid_idx = idx\n",
    "        botmid_idx = idx + iicxn\n",
    "\n",
    "        topright_idx = idx - iicxn + 1\n",
    "        midright_idx = idx + 1\n",
    "        botright_idx = idx + iicxn + 1\n",
    "\n",
    "        if cnt_x == 0:\n",
    "            topleft_idx += iicxn - 1\n",
    "            midleft_idx += iicxn - 1\n",
    "            botleft_idx += iicxn - 1\n",
    "\n",
    "            ne_topleft += iicxn - 1\n",
    "            ne_botleft += iicxn - 1\n",
    "\n",
    "        if cnt_x == (iicxn - 1):\n",
    "            topright_idx -= iicxn - 1\n",
    "            midright_idx -= iicxn - 1\n",
    "            botright_idx -= iicxn - 1\n",
    "\n",
    "            ne_topright -= iicxn - 1\n",
    "            ne_botright -= iicxn - 1\n",
    "\n",
    "        if cnt_y == 0:\n",
    "            topleft_idx += ((iicxn) * (iicyn - 1))\n",
    "            topmid_idx += ((iicxn) * (iicyn - 1))\n",
    "            topright_idx += ((iicxn) * (iicyn - 1))\n",
    "\n",
    "            ne_topleft += ((iicxn) * (iicyn - 1))\n",
    "            ne_topright += ((iicxn) * (iicyn - 1))\n",
    "\n",
    "        if cnt_y == (iicyn - 1):\n",
    "            botleft_idx -= ((iicxn) * (iicyn - 1))\n",
    "            botmid_idx -= ((iicxn) * (iicyn - 1))\n",
    "            botright_idx -= ((iicxn) * (iicyn - 1))\n",
    "\n",
    "            ne_botleft -= ((iicxn) * (iicyn - 1))\n",
    "            ne_botright -= ((iicxn) * (iicyn - 1))\n",
    "\n",
    "        topleft = p[topleft_idx]\n",
    "        midleft = p[midleft_idx]\n",
    "        botleft = p[botleft_idx]\n",
    "\n",
    "        topmid = p[topmid_idx]\n",
    "        midmid = p[midmid_idx]\n",
    "        botmid = p[botmid_idx]\n",
    "\n",
    "        topright = p[topright_idx]\n",
    "        midright = p[midright_idx]\n",
    "        botright = p[botright_idx]\n",
    "\n",
    "        hplusx_topleft = hplusx[ne_topleft]\n",
    "        hplusx_botleft = hplusx[ne_botleft]\n",
    "        hplusy_topleft = hplusy[ne_topleft]\n",
    "        hplusy_botleft = hplusy[ne_botleft]\n",
    "\n",
    "        hplusx_topright = hplusx[ne_topright]\n",
    "        hplusx_botright = hplusx[ne_botright]\n",
    "        hplusy_topright = hplusy[ne_topright]\n",
    "        hplusy_botright = hplusy[ne_botright]\n",
    "\n",
    "        cxx_tl = cxx[ne_topleft]\n",
    "        cxx_tr = cxx[ne_topright]\n",
    "        cxx_bl = cxx[ne_botleft]\n",
    "        cxx_br = cxx[ne_botright]\n",
    "\n",
    "        cxy_tl = cxy[ne_topleft]\n",
    "        cxy_tr = cxy[ne_topright]\n",
    "        cxy_bl = cxy[ne_botleft]\n",
    "        cxy_br = cxy[ne_botright]\n",
    "\n",
    "        cyx_tl = cyx[ne_topleft]\n",
    "        cyx_tr = cyx[ne_topright]\n",
    "        cyx_bl = cyx[ne_botleft]\n",
    "        cyx_br = cyx[ne_botright]\n",
    "\n",
    "        cyy_tl = cyy[ne_topleft]\n",
    "        cyy_tr = cyy[ne_topright]\n",
    "        cyy_bl = cyy[ne_botleft]\n",
    "        cyy_br = cyy[ne_botright]\n",
    "\n",
    "        if x_wall and (cnt_x == 0):\n",
    "            hplusx_topleft = 0.\n",
    "            hplusy_topleft = 0.\n",
    "            hplusx_botleft = 0.\n",
    "            hplusy_botleft = 0.\n",
    "\n",
    "        if x_wall and (cnt_x == (iicxn - 1)):\n",
    "            hplusx_topright = 0.\n",
    "            hplusy_topright = 0.\n",
    "            hplusx_botright = 0.\n",
    "            hplusy_botright = 0.\n",
    "\n",
    "        if y_wall and (cnt_y == 0):\n",
    "            hplusx_topleft = 0.\n",
    "            hplusy_topleft = 0.\n",
    "            hplusx_topright = 0.\n",
    "            hplusy_topright = 0.\n",
    "\n",
    "        if y_wall and (cnt_y == (iicyn - 1)):\n",
    "            hplusx_botleft = 0.\n",
    "            hplusy_botleft = 0.\n",
    "            hplusx_botright = 0.\n",
    "            hplusy_botright = 0.\n",
    "\n",
    "        Dx_tl = 0.5 * (topmid - topleft + midmid - midleft) * hplusx_topleft\n",
    "        Dx_tr = 0.5 * (topright - topmid + midright - midmid) * hplusx_topright\n",
    "        Dx_bl = 0.5 * (botmid - botleft + midmid - midleft) * hplusx_botleft\n",
    "        Dx_br = 0.5 * (botright - botmid + midright - midmid) * hplusx_botright\n",
    "\n",
    "        Dy_tl = 0.5 * (midmid - topmid + midleft - topleft) * hplusy_topleft\n",
    "        Dy_tr = 0.5 * (midright - topright + midmid - topmid) * hplusy_topright\n",
    "        Dy_bl = 0.5 * (botmid - midmid + botleft - midleft) * hplusy_botleft\n",
    "        Dy_br = 0.5 * (botright - midright + botmid - midmid) * hplusy_botright\n",
    "\n",
    "        fac = 1.0\n",
    "        Dxx = 0.5 * (cxx_tr * Dx_tr - cxx_tl * Dx_tl + cxx_br * Dx_br - cxx_bl * Dx_bl) * oodx * oodx * fac\n",
    "        Dyy = 0.5 * (cyy_br * Dy_br - cyy_tr * Dy_tr + cyy_bl * Dy_bl - cyy_tl * Dy_tl) * oody * oody * fac\n",
    "        Dyx = 0.5 * (cyx_br * Dy_br - cyx_bl * Dy_bl + cyx_tr * Dy_tr - cyx_tl * Dy_tl) * oody * oodx * fac\n",
    "        Dxy = 0.5 * (cxy_br * Dx_br - cxy_tr * Dx_tr + cxy_bl * Dy_bl - cxy_tl * Dx_tl) * oodx * oody * fac\n",
    "\n",
    "        lap[idx] = Dxx + Dyy + Dyx + Dxy + hcenter[idx] * p[idx]\n",
    "\n",
    "        lap[idx] *= diag_inv[idx]\n",
    "\n",
    "        cnt_x += 1\n",
    "        if cnt_x % iicxn == 0:\n",
    "            cnt_y += 1\n",
    "            cnt_x = 0\n",
    "\n",
    "    return lap\n",
    "\n",
    "# ==========================================================================\n",
    "# 3. Comparison Test Setup\n",
    "# ==========================================================================\n",
    "\n",
    "print(\"Setting up comparison test...\")\n",
    "\n",
    "# Grid parameters\n",
    "nx = 20  # Inner cells x\n",
    "ny = 15  # Inner cells y\n",
    "igx = 2  # Ghost cells x (assuming 1 layer)\n",
    "igy = 2  # Ghost cells y\n",
    "dx = 0.1\n",
    "dy = 0.12\n",
    "dz = 1.0 # For 2D scaling consistency if needed\n",
    "oodx = 1.0 / dx\n",
    "oody = 1.0 / dy\n",
    "\n",
    "# Physics/Solver parameters\n",
    "dt = 0.01\n",
    "coriolis_params = (0.0, 0.0, 0.0) # f_x, f_y, f_z -> Set to zero for simpler test\n",
    "\n",
    "# Boundary Conditions\n",
    "is_x_periodic = True\n",
    "is_y_periodic = True\n",
    "is_x_wall = not is_x_periodic\n",
    "is_y_wall = not is_y_periodic\n",
    "\n",
    "# --- Generate Consistent Data ---\n",
    "\n",
    "# Nodal Pressure (including ghost/boundary nodes)\n",
    "# p_nodal = np.random.rand(nx +1 + 2*igx, ny+1 + 2*igy)\n",
    "p_nodal = np.random.rand(nx  + 2*igx, ny + 2*igy)\n",
    "\n",
    "# Cell-centered coefficient 'pTheta' (used for hplusx, hplusy)\n",
    "pTheta_cell = calculate_pTheta_placeholder(nx, ny)\n",
    "\n",
    "# Nodal Helmholtz coefficient 'helmholtz_coeff_nodal' (used for hcenter)\n",
    "helmholtz_coeff_nodal = calculate_helmholtz_coeff_placeholder(nx, ny) # Shape (nx+1, ny+1)\n",
    "\n",
    "# Boundary factors Xbot, Xtop (placeholder, size nx)\n",
    "Xbot = np.ones(nx)\n",
    "Xtop = np.ones(nx)\n",
    "if is_y_wall: # Simple mimic of C code logic\n",
    "    Xbot *= 0.5 # Example scaling factor\n",
    "    Xtop *= 0.5\n",
    "\n",
    "# --- Prepare Inputs for New Laplacian Function ---\n",
    "# (Uses data in its natural grid locations)\n",
    "\n",
    "# --- Prepare Inputs for lap2D_gather ---\n",
    "iicxn = nx\n",
    "iicyn = ny\n",
    "p_nodal_flat = p_nodal.flatten() # Flatten the full nodal array\n",
    "\n",
    "# lap2D_gather coefficients (need to be flattened inner arrays, size nx*ny)\n",
    "# Use pTheta for hplusx, hplusy\n",
    "hplusx_flat = pTheta_cell.flatten()\n",
    "hplusy_flat = pTheta_cell.flatten()\n",
    "\n",
    "# Use inner part of helmholtz_coeff for hcenter\n",
    "hcenter_flat = helmholtz_coeff_nodal[igy:ny+igy, igx:nx+igx].flatten()\n",
    "\n",
    "# Placeholder for diag_inv (set to 1.0 for no effect)\n",
    "diag_inv_flat = np.ones(nx * ny)\n",
    "\n",
    "# Coriolis components for lap2D_gather (flattened, size nx*ny)\n",
    "# Order: cyy, cxx, cyx, cxy. Set to zero consistent with coriolis_params=(0,0,0)\n",
    "cyy_flat = np.zeros(nx * ny)\n",
    "cxx_flat = np.zeros(nx * ny)\n",
    "cyx_flat = np.zeros(nx * ny)\n",
    "cxy_flat = np.zeros(nx * ny)\n",
    "coriolis_gather_tuple = (cyy_flat, cxx_flat, cyx_flat, cxy_flat)\n",
    "\n",
    "# ==========================================================================\n",
    "# 4. Run Calculations\n",
    "# ==========================================================================\n",
    "\n",
    "print(\"\\nRunning New Laplacian Method...\")\n",
    "result_new = calculate_new_laplacian_action(\n",
    "    p_nodal,\n",
    "    pTheta_cell,\n",
    "    helmholtz_coeff_nodal,\n",
    "    dx, dy, dz, dt, nx, ny,\n",
    "    coriolis_params,\n",
    "    Xbot, Xtop,\n",
    "    is_x_periodic, is_y_periodic\n",
    ")\n",
    "print(\"Done.\")\n",
    "\n",
    "print(\"\\nRunning lap2D_gather Method...\")\n",
    "# Ensure lap2D_gather uses consistent parameters\n",
    "try:\n",
    "    result_gather_flat = lap2D_gather(\n",
    "        p_nodal_flat, # Pass full flattened nodal p\n",
    "        igx, igy,\n",
    "        iicxn, iicyn,\n",
    "        hplusx_flat, hplusy_flat, hcenter_flat,\n",
    "        oodx, oody,\n",
    "        is_x_periodic, is_y_periodic, is_x_wall, is_y_wall,\n",
    "        diag_inv_flat,\n",
    "        coriolis_gather_tuple\n",
    "    )\n",
    "    result_gather = result_gather_flat.reshape((ny, nx)) # Reshape to (ny, nx)\n",
    "    print(\"Done.\")\n",
    "\n",
    "    # ==========================================================================\n",
    "    # 5. Compare Results\n",
    "    # ==========================================================================\n",
    "    print(\"\\nComparing results (New Laplacian vs lap2D_gather):\")\n",
    "\n",
    "    # Ensure shapes match (result_new should be (nx, ny) from divergence)\n",
    "    if result_new.shape == (nx, ny):\n",
    "         result_new_compare = result_new.T # Transpose to match (ny, nx)\n",
    "    elif result_new.shape == (ny, nx):\n",
    "         result_new_compare = result_new\n",
    "    else:\n",
    "         print(f\"ERROR: Unexpected shape for result_new: {result_new.shape}\")\n",
    "         result_new_compare = None\n",
    "\n",
    "\n",
    "    inslice = tuple([slice(4,-4)]*2)\n",
    "\n",
    "    if result_new_compare is not None and result_gather.shape == result_new_compare.shape:\n",
    "        difference = np.abs(result_new_compare[inslice] - result_gather[inslice])\n",
    "        max_abs_diff = np.max(difference)\n",
    "        mean_abs_diff = np.mean(difference)\n",
    "        max_rel_diff = np.max(difference / (np.abs(result_gather[inslice]) + 1e-15)) # Avoid division by zero\n",
    "\n",
    "        print(f\"Max: {np.max(result_new_compare):.6e}\")\n",
    "        print(f\"Min:  {np.min(result_new_compare):.6e}\")\n",
    "        print(f\"Mean: {np.mean(result_new_compare):.6e}\")\n",
    "\n",
    "        print(f\"Shapes: New={result_new_compare.shape}, Gather={result_gather.shape}\")\n",
    "        print(f\"Maximum absolute difference: {max_abs_diff:.6e}\")\n",
    "        print(f\"Mean absolute difference:  {mean_abs_diff:.6e}\")\n",
    "        print(f\"Maximum relative difference: {max_rel_diff:.6e}\")\n",
    "\n",
    "        # Adjust tolerance as needed\n",
    "        if np.allclose(result_new_compare, result_gather, rtol=1e-6, atol=1e-8):\n",
    "            print(\"\\nResults are numerically close!\")\n",
    "        else:\n",
    "            print(\"\\nResults differ significantly.\")\n",
    "            # Optional: Print indices where difference is large\n",
    "            # max_diff_idx = np.unravel_index(np.argmax(difference), difference.shape)\n",
    "            # print(f\"Max difference at index {max_diff_idx}:\")\n",
    "            # print(f\"  New Laplacian: {result_new_compare[max_diff_idx]}\")\n",
    "            # print(f\"  lap2D_gather: {result_gather[max_diff_idx]}\")\n",
    "    else:\n",
    "        print(\"ERROR: Shapes do not match for comparison.\")\n",
    "        print(f\"Shapes: New (transposed)={result_new_compare.shape if result_new_compare is not None else 'N/A'}, Gather={result_gather.shape}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"\\nAn error occurred during lap2D_gather execution or comparison:\")\n",
    "    print(e)\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ],
   "id": "5202f45ffb4bbc44",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up comparison test...\n",
      "INFO: Using placeholder for pTheta coefficient.\n",
      "INFO: Using placeholder for Helmholtz coefficient.\n",
      "\n",
      "Running New Laplacian Method...\n",
      "INFO: Using placeholder (identity) for Coriolis transform.\n",
      "Done.\n",
      "\n",
      "Running lap2D_gather Method...\n",
      "Done.\n",
      "\n",
      "Comparing results (New Laplacian vs lap2D_gather):\n",
      "Max: 7.113838e-01\n",
      "Min:  -7.036523e-01\n",
      "Mean: 2.559678e-02\n",
      "Shapes: New=(15, 20), Gather=(15, 20)\n",
      "Maximum absolute difference: 3.215502e+228\n",
      "Mean absolute difference:  3.827979e+226\n",
      "Maximum relative difference: 1.871631e+14\n",
      "\n",
      "Results differ significantly.\n"
     ]
    }
   ],
   "execution_count": 72
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8276ad805ef67dd0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T18:02:22.184640Z",
     "start_time": "2025-04-15T18:02:22.180605Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from typing import Tuple\n",
    "\n",
    "def gradient_2d_numpy(p: np.ndarray, dx: float, dy: float) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Calculate the discrete gradient of a 2D scalar field using NumPy slicing.\n",
    "\n",
    "    The gradient is calculated at cell centers based on nodal values of p.\n",
    "     mimics the calculation specified in eq. (30a) in BK19 paper for 2D.\n",
    "\n",
    "    Dpx[i, j] = (p[i+1, j] + p[i+1, j+1] - p[i, j] - p[i, j+1]) * 0.5 / dx\n",
    "    Dpy[i, j] = (p[i, j+1] + p[i+1, j+1] - p[i, j] - p[i+1, j]) * 0.5 / dy\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    p : np.ndarray of shape (nx+1, ny+1)\n",
    "        The nodal scalar field.\n",
    "    dx : float\n",
    "        Grid spacing in the x-direction.\n",
    "    dy : float\n",
    "        Grid spacing in the y-direction.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[np.ndarray, np.ndarray]\n",
    "        The gradient components (Dpx, Dpy), each of shape (nx, ny).\n",
    "        The gradient is defined on cells.\n",
    "    \"\"\"\n",
    "    if p.ndim != 2:\n",
    "        raise ValueError(f\"Input array p must be 2D, but got ndim={p.ndim}\")\n",
    "\n",
    "    # Calculate Dpx using array slicing\n",
    "    # Dpx represents the average gradient across the cell in x-direction\n",
    "    # It averages (p[i+1, j] - p[i, j])/dx and (p[i+1, j+1] - p[i, j+1])/dx\n",
    "    term1_px = p[1:, :-1]  # p[i+1, j]\n",
    "    term2_px = p[1:, 1:]   # p[i+1, j+1]\n",
    "    term3_px = p[:-1, :-1] # p[i, j]\n",
    "    term4_px = p[:-1, 1:]  # p[i, j+1]\n",
    "    Dpx = (term1_px + term2_px - term3_px - term4_px) * (0.5 / dx)\n",
    "\n",
    "    # Calculate Dpy using array slicing\n",
    "    # Dpy represents the average gradient across the cell in y-direction\n",
    "    # It averages (p[i, j+1] - p[i, j])/dy and (p[i+1, j+1] - p[i+1, j])/dy\n",
    "    term1_py = p[:-1, 1:]  # p[i, j+1]\n",
    "    term2_py = p[1:, 1:]   # p[i+1, j+1]\n",
    "    term3_py = p[:-1, :-1] # p[i, j]\n",
    "    term4_py = p[1:, :-1]  # p[i+1, j]\n",
    "    Dpy = (term1_py + term2_py - term3_py - term4_py) * (0.5 / dy)\n",
    "\n",
    "    return Dpx, Dpy"
   ],
   "id": "9bcf5d8a70a7a8e5",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T18:13:47.337359Z",
     "start_time": "2025-04-15T18:13:47.332353Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import numba\n",
    "from typing import Tuple\n",
    "\n",
    "@numba.njit(cache=True, fastmath=True, nogil=True)\n",
    "def gradient_2d_numba(p: np.ndarray, dx: float, dy: float) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Numba kernel for 2D gradient (cell-centered).\"\"\"\n",
    "    nx = p.shape[0] - 1\n",
    "    ny = p.shape[1] - 1\n",
    "    if nx < 0 or ny < 0:\n",
    "         return (np.empty((max(0,nx), max(0,ny)), dtype=p.dtype),\n",
    "                 np.empty((max(0,nx), max(0,ny)), dtype=p.dtype))\n",
    "    if nx == 0 or ny == 0:\n",
    "         return (np.empty((nx, ny), dtype=p.dtype),\n",
    "                 np.empty((nx, ny), dtype=p.dtype))\n",
    "\n",
    "\n",
    "    Dpx = np.empty((nx, ny), dtype=p.dtype)\n",
    "    Dpy = np.empty((nx, ny), dtype=p.dtype)\n",
    "\n",
    "    inv_dx_half = 0.5 / dx\n",
    "    inv_dy_half = 0.5 / dy\n",
    "\n",
    "    for i in range(nx):\n",
    "        for j in range(ny):\n",
    "            p_i_j     = p[i, j]\n",
    "            p_ip1_j   = p[i+1, j]\n",
    "            p_i_jp1   = p[i, j+1]\n",
    "            p_ip1_jp1 = p[i+1, j+1]\n",
    "\n",
    "            # Dpx = avg gradient in x across the cell (i,j)\n",
    "            Dpx[i, j] = (p_ip1_j + p_ip1_jp1 - p_i_j - p_i_jp1) * inv_dx_half\n",
    "            # Dpy = avg gradient in y across the cell (i,j)\n",
    "            Dpy[i, j] = (p_i_jp1 + p_ip1_jp1 - p_i_j - p_ip1_j) * inv_dy_half\n",
    "\n",
    "    return Dpx, Dpy"
   ],
   "id": "15ba4489454b1cab",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T18:13:56.378779Z",
     "start_time": "2025-04-15T18:13:55.615712Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import numba\n",
    "import timeit\n",
    "import functools # To use partial for timeit setup\n",
    "\n",
    "# --- Include the function definitions from above ---\n",
    "# def gradient_2d_numpy(p: np.ndarray, dx: float, dy: float) -> Tuple[np.ndarray, np.ndarray]: ...\n",
    "# @numba.njit(cache=True, fastmath=True)\n",
    "# def gradient_2d_numba(p: np.ndarray, dx: float, dy: float) -> Tuple[np.ndarray, np.ndarray]: ...\n",
    "# --- Assume they are defined here ---\n",
    "\n",
    "# --- Setup Parameters ---\n",
    "nx, ny = 500, 500  # Grid size (number of cells)\n",
    "dx, dy = 0.01, 0.01 # Grid spacing\n",
    "\n",
    "# Create sample nodal data (shape nx+1, ny+1)\n",
    "p_nodal = np.random.rand(nx + 1, ny + 1)\n",
    "\n",
    "print(f\"Benchmarking on a grid of size: ({nx} x {ny}) cells\")\n",
    "print(f\"Input array shape: {p_nodal.shape}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# --- Correctness Check (Important!) ---\n",
    "Dpx_np, Dpy_np = gradient_2d_numpy(p_nodal, dx, dy)\n",
    "# Run Numba once for compilation (warm-up)\n",
    "Dpx_nb, Dpy_nb = gradient_2d_numba(p_nodal, dx, dy)\n",
    "\n",
    "try:\n",
    "    np.testing.assert_allclose(Dpx_np, Dpx_nb, rtol=1e-10, atol=1e-12)\n",
    "    np.testing.assert_allclose(Dpy_np, Dpy_nb, rtol=1e-10, atol=1e-12)\n",
    "    print(\"Correctness check PASSED: NumPy and Numba results are close.\")\n",
    "except AssertionError as e:\n",
    "    print(f\"Correctness check FAILED: {e}\")\n",
    "    # Decide whether to proceed with benchmarking if results differ\n",
    "    # exit() # Optional: stop if results don't match\n",
    "\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# --- Benchmarking ---\n",
    "n_runs = 100 # Number of times to execute the function within one timeit measurement\n",
    "n_repeat = 7 # Number of times to repeat the measurement\n",
    "\n",
    "# Use functools.partial to pass arguments to the functions being timed\n",
    "numpy_timer = timeit.Timer(functools.partial(gradient_2d_numpy, p_nodal, dx, dy))\n",
    "numba_timer = timeit.Timer(functools.partial(gradient_2d_numba, p_nodal, dx, dy))\n",
    "\n",
    "# Time the NumPy version\n",
    "try:\n",
    "    numpy_times = numpy_timer.repeat(repeat=n_repeat, number=n_runs)\n",
    "    numpy_avg_time = np.mean(numpy_times) / n_runs\n",
    "    numpy_std_time = np.std(numpy_times) / n_runs\n",
    "    print(f\"NumPy Version:\")\n",
    "    print(f\"  Average time: {numpy_avg_time:.6f} seconds\")\n",
    "    print(f\"  Std dev:      {numpy_std_time:.6f} seconds\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not benchmark NumPy version: {e}\")\n",
    "\n",
    "\n",
    "# Time the Numba version (already compiled during warm-up)\n",
    "try:\n",
    "    numba_times = numba_timer.repeat(repeat=n_repeat, number=n_runs)\n",
    "    numba_avg_time = np.mean(numba_times) / n_runs\n",
    "    numba_std_time = np.std(numba_times) / n_runs\n",
    "    print(f\"Numba Version:\")\n",
    "    print(f\"  Average time: {numba_avg_time:.6f} seconds\")\n",
    "    print(f\"  Std dev:      {numba_std_time:.6f} seconds\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not benchmark Numba version: {e}\")\n",
    "\n",
    "\n",
    "# --- Comparison ---\n",
    "print(\"-\" * 30)\n",
    "if 'numpy_avg_time' in locals() and 'numba_avg_time' in locals():\n",
    "    speedup = numpy_avg_time / numba_avg_time\n",
    "    print(f\"Numba speedup over NumPy: {speedup:.2f}x\")\n",
    "elif 'numba_avg_time' not in locals():\n",
    "     print(\"Cannot calculate speedup because Numba benchmark failed.\")\n",
    "else:\n",
    "     print(\"Cannot calculate speedup because NumPy benchmark failed.\")"
   ],
   "id": "d337047504274887",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmarking on a grid of size: (500 x 500) cells\n",
      "Input array shape: (501, 501)\n",
      "------------------------------\n",
      "Correctness check PASSED: NumPy and Numba results are close.\n",
      "------------------------------\n",
      "NumPy Version:\n",
      "  Average time: 0.000969 seconds\n",
      "  Std dev:      0.000035 seconds\n",
      "Numba Version:\n",
      "  Average time: 0.000098 seconds\n",
      "  Std dev:      0.000002 seconds\n",
      "------------------------------\n",
      "Numba speedup over NumPy: 9.88x\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T19:06:37.601714Z",
     "start_time": "2025-04-15T19:06:37.594337Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from typing import List, Tuple\n",
    "\n",
    "def derivative_np(variable: np.ndarray, axis: int, ndim: int, dxyz: List[float]):\n",
    "    \"\"\"Standalone NumPy version of the derivative function.\n",
    "\n",
    "    Calculates the nodal derivative of the given cell variable in the given direction.\n",
    "    Logic matches the original class method.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    variable : np.ndarray\n",
    "        The cell-centered values. Shape (nx, [ny], [nz]).\n",
    "    axis : int\n",
    "        Axis along which to differentiate (0, 1, or 2).\n",
    "    ndim : int\n",
    "        Number of dimensions (1, 2, or 3).\n",
    "    dxyz : List[float]\n",
    "        List of grid spacings [dx, dy, dz].\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Nodal derivative. Shape (nx-1, [ny-1], [nz-1]).\n",
    "    \"\"\"\n",
    "    if axis >= ndim:\n",
    "        raise ValueError(f\"Axis {axis} is out of bounds for ndim {ndim}\")\n",
    "    if len(dxyz) < ndim:\n",
    "        raise ValueError(f\"dxyz must have at least {ndim} elements for ndim={ndim}\")\n",
    "\n",
    "    # Discretization fineness\n",
    "    ds = dxyz[axis]\n",
    "    if ds == 0:\n",
    "        # Handle potential division by zero if dx is zero\n",
    "        # Returning zeros of the expected shape might be one approach\n",
    "        print(\"Warning: ds is zero in derivative_np. Returning zeros.\")\n",
    "        out_shape = tuple(s - 1 for s in variable.shape)\n",
    "        return np.zeros(out_shape, dtype=variable.dtype)\n",
    "\n",
    "\n",
    "    # Bring the differentiation axis to the front.\n",
    "    u_flat = np.moveaxis(variable, axis, 0)\n",
    "\n",
    "    # Compute the primary difference along the first axis.\n",
    "    # Use np.diff which computes x[1:] - x[:-1]\n",
    "    d = np.diff(u_flat, axis=0) / ds\n",
    "\n",
    "    # Based on the dimensionality, average over the complementary axes.\n",
    "    if ndim == 1:\n",
    "        # 1D case: no additional averaging required. d shape (nx-1,)\n",
    "        result = d\n",
    "    elif ndim == 2:\n",
    "        # 2D case: average along the second axis (which was not axis 0).\n",
    "        # d has shape (n-1, m) if axis=0, or (m-1, n) if axis=1.\n",
    "        # Average is always along the second dimension of d.\n",
    "        if d.shape[1] < 2: # Check if averaging is possible\n",
    "             result = np.empty(d.shape[:-1] + (0,), dtype=d.dtype) # Resulting shape has 0 size in the averaged dim\n",
    "        else:\n",
    "             result = 0.5 * (d[:, :-1] + d[:, 1:]) # Result shape (n-1, m-1)\n",
    "    elif ndim == 3:\n",
    "        # 3D case: average along both the second and third axes.\n",
    "        # d has shape (n-1, m, p) or similar permutations.\n",
    "        # Average is always along the second and third dimensions of d.\n",
    "        if d.shape[1] < 2 or d.shape[2] < 2: # Check if averaging is possible\n",
    "             out_shape_list = list(d.shape)\n",
    "             if d.shape[1] < 2: out_shape_list[1] = 0\n",
    "             else: out_shape_list[1] -= 1\n",
    "             if d.shape[2] < 2: out_shape_list[2] = 0\n",
    "             else: out_shape_list[2] -= 1\n",
    "             result = np.empty(tuple(out_shape_list), dtype=d.dtype)\n",
    "        else:\n",
    "            result = (\n",
    "                d[:, :-1, :-1] + d[:, :-1, 1:] + d[:, 1:, :-1] + d[:, 1:, 1:]\n",
    "            ) / 4.0 # Result shape (n-1, m-1, p-1)\n",
    "    else:\n",
    "        raise ValueError(\"Only 1D, 2D, or 3D arrays are supported.\")\n",
    "\n",
    "    # Move the differentiation axis back to its original location if ndim > 1.\n",
    "    # If ndim=1, result is 1D, moveaxis isn't needed/meaningful here.\n",
    "    if result.ndim > 0 and result.ndim == variable.ndim: # Only move if result has dims and matches original rank\n",
    "         # Need to calculate the correct target axis after averaging reduction\n",
    "         original_axes = list(range(variable.ndim))\n",
    "         target_axis = original_axes[axis]\n",
    "         return np.moveaxis(result, 0, target_axis)\n",
    "    else:\n",
    "        # Handle cases where dimensions were reduced (e.g. 2D input, ny=1 -> 1D output)\n",
    "        # Or the 1D case where moveaxis isn't needed.\n",
    "        return result\n",
    "\n",
    "\n",
    "def divergence_np(vector: np.ndarray, ndim: int, dxyz: List[float]) -> np.ndarray:\n",
    "    \"\"\"Standalone NumPy version of the divergence function.\n",
    "\n",
    "    Calculates the divergence of the cell-centered vector using derivative_np.\n",
    "    Logic matches the original class method.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    vector : np.ndarray\n",
    "        The cell-centered vector field. Shape (nx, [ny], [nz], ndim).\n",
    "    ndim : int\n",
    "        Number of dimensions (1, 2, or 3).\n",
    "    dxyz : List[float]\n",
    "        List of grid spacings [dx, dy, dz].\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Divergence evaluated at the nodes. Shape (nx-1, [ny-1], [nz-1]).\n",
    "    \"\"\"\n",
    "    if vector.shape[-1] != ndim:\n",
    "        raise ValueError(\n",
    "            f\"Last dim of vector ({vector.shape[-1]}) must match ndim ({ndim}).\"\n",
    "        )\n",
    "    if vector.ndim != ndim + 1:\n",
    "        raise ValueError(\n",
    "            f\"Vector dimensions ({vector.ndim}) must be ndim+1 ({ndim+1}).\"\n",
    "            )\n",
    "\n",
    "    # Determine output shape: (nx-1, [ny-1], [nz-1])\n",
    "    # Need to handle cases where input shape might be 1 in some dims\n",
    "    output_shape = tuple(max(0, s - 1) for s in vector.shape[:-1])\n",
    "\n",
    "    # Pre-allocation.\n",
    "    Ux = np.zeros(output_shape, dtype=vector.dtype)\n",
    "\n",
    "    # Calculate divergence by summing derivatives\n",
    "    for axis in range(ndim):\n",
    "        component = vector[..., axis]\n",
    "        # Ensure component has the correct dimensions before passing\n",
    "        if component.ndim != ndim:\n",
    "             raise RuntimeError(f\"Internal error: Component slice has unexpected ndim {component.ndim}\")\n",
    "        deriv_component = derivative_np(component, axis, ndim, dxyz)\n",
    "\n",
    "        # Check if shapes match before adding (can happen if input dims were 1)\n",
    "        if deriv_component.shape == Ux.shape:\n",
    "             Ux += deriv_component\n",
    "        elif Ux.size == 0 and deriv_component.size == 0:\n",
    "             pass # Adding zero to zero is fine\n",
    "        else:\n",
    "            # This case indicates an issue, likely due to input dimensions being 1\n",
    "            # which causes derivative_np to return a shape incompatible with the pre-allocated Ux\n",
    "             raise RuntimeError(f\"Shape mismatch adding derivative component. Ux shape: {Ux.shape}, deriv_component shape: {deriv_component.shape}. Check input dimensions.\")\n",
    "\n",
    "\n",
    "    return Ux"
   ],
   "id": "c4bb295bef0d66d6",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T19:06:47.630179Z",
     "start_time": "2025-04-15T19:06:47.625418Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numba\n",
    "\n",
    "# Copied from previous answer for completeness\n",
    "@numba.njit(cache=True, fastmath=True, nogil=True)\n",
    "def _divergence_node_centered_2d_numba(\n",
    "    vector_field: np.ndarray, # Shape (nx, ny, 2) - Cell-centered\n",
    "    dx: float,\n",
    "    dy: float\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calculates 2D divergence at nodes based on cell-centered vector components.\n",
    "    Output shape: (nx-1, ny-1) - Node-centered\n",
    "    \"\"\"\n",
    "    nx, ny = vector_field.shape[0], vector_field.shape[1]\n",
    "    nnx = max(0, nx - 1)\n",
    "    nny = max(0, ny - 1)\n",
    "    dtype = vector_field.dtype\n",
    "\n",
    "    if nnx == 0 or nny == 0:\n",
    "        return np.empty((nnx, nny), dtype=dtype)\n",
    "\n",
    "    div_result = np.empty((nnx, nny), dtype=dtype)\n",
    "    inv_dx = 1.0 / dx if dx != 0 else 0.0\n",
    "    inv_dy = 1.0 / dy if dy != 0 else 0.0\n",
    "    scale_xy = 0.5 # Averaging factor\n",
    "\n",
    "    u = vector_field[:, :, 0] # Component along axis 0\n",
    "    v = vector_field[:, :, 1] # Component along axis 1\n",
    "\n",
    "    for i in range(nnx): # Node index i\n",
    "        for j in range(nny): # Node index j\n",
    "            # Term d(u)/dx: diff along axis 0, average along axis 1\n",
    "            diff_u_j   = (u[i+1, j]   - u[i, j])\n",
    "            diff_u_jp1 = (u[i+1, j+1] - u[i, j+1])\n",
    "            term_x = scale_xy * (diff_u_j + diff_u_jp1) * inv_dx\n",
    "\n",
    "            # Term d(v)/dy: diff along axis 1, average along axis 0\n",
    "            diff_v_i   = (v[i,   j+1] - v[i,   j])\n",
    "            diff_v_ip1 = (v[i+1, j+1] - v[i+1, j])\n",
    "            term_y = scale_xy * (diff_v_i + diff_v_ip1) * inv_dy\n",
    "\n",
    "            div_result[i, j] = term_x + term_y\n",
    "\n",
    "    return div_result"
   ],
   "id": "fa8ee26da91b4e5e",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-15T19:06:58.680581Z",
     "start_time": "2025-04-15T19:06:57.620832Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import timeit\n",
    "import functools\n",
    "\n",
    "# --- Setup Parameters (2D) ---\n",
    "nx, ny = 500, 500  # Grid size (number of cells)\n",
    "dx, dy = 0.01, 0.02 # Grid spacing\n",
    "ndim = 2\n",
    "dxyz = [dx, dy]\n",
    "\n",
    "# Create sample cell-centered vector data\n",
    "vector_2d_cells = np.random.rand(nx, ny, ndim) # Shape (nx, ny, 2)\n",
    "\n",
    "print(f\"Benchmarking on a cell grid of size: ({nx} x {ny})\")\n",
    "print(f\"Input vector shape: {vector_2d_cells.shape}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# --- Correctness Check ---\n",
    "print(\"Running correctness check...\")\n",
    "try:\n",
    "    div_np = divergence_np(vector_2d_cells, ndim, dxyz)\n",
    "    # Run Numba once for compilation (warm-up)\n",
    "    div_nb = _divergence_node_centered_2d_numba(vector_2d_cells, dx, dy)\n",
    "\n",
    "    np.testing.assert_allclose(div_np, div_nb, rtol=1e-12, atol=1e-14)\n",
    "    print(\"Correctness check PASSED: NumPy and Numba results are close.\")\n",
    "    print(f\"Output shape: {div_np.shape}\") # Should be (nx-1, ny-1)\n",
    "except Exception as e:\n",
    "    print(f\"Correctness check FAILED: {e}\")\n",
    "    # Decide whether to proceed\n",
    "    exit() # Stop if results don't match\n",
    "\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# --- Benchmarking ---\n",
    "n_runs = 50 # Number of times to execute the function within one timeit measurement\n",
    "n_repeat = 7 # Number of times to repeat the measurement\n",
    "\n",
    "# Use functools.partial to pass arguments\n",
    "numpy_timer = timeit.Timer(functools.partial(divergence_np, vector_2d_cells, ndim, dxyz))\n",
    "# Numba function only needs vector, dx, dy\n",
    "numba_timer = timeit.Timer(functools.partial(_divergence_node_centered_2d_numba, vector_2d_cells, dx, dy))\n",
    "\n",
    "# Time the NumPy version\n",
    "try:\n",
    "    numpy_times = numpy_timer.repeat(repeat=n_repeat, number=n_runs)\n",
    "    numpy_avg_time = np.mean(numpy_times) / n_runs\n",
    "    numpy_std_time = np.std(numpy_times) / n_runs\n",
    "    print(f\"NumPy Standalone Version:\")\n",
    "    print(f\"  Average time: {numpy_avg_time:.6f} seconds\")\n",
    "    print(f\"  Std dev:      {numpy_std_time:.6f} seconds\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not benchmark NumPy version: {e}\")\n",
    "\n",
    "\n",
    "# Time the Numba version (already compiled during warm-up)\n",
    "try:\n",
    "    numba_times = numba_timer.repeat(repeat=n_repeat, number=n_runs)\n",
    "    numba_avg_time = np.mean(numba_times) / n_runs\n",
    "    numba_std_time = np.std(numba_times) / n_runs\n",
    "    print(f\"Numba 2D Kernel Version:\")\n",
    "    print(f\"  Average time: {numba_avg_time:.6f} seconds\")\n",
    "    print(f\"  Std dev:      {numba_std_time:.6f} seconds\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not benchmark Numba version: {e}\")\n",
    "\n",
    "\n",
    "# --- Comparison ---\n",
    "print(\"-\" * 30)\n",
    "if 'numpy_avg_time' in locals() and 'numba_avg_time' in locals():\n",
    "    speedup = numpy_avg_time / numba_avg_time\n",
    "    print(f\"Numba speedup over NumPy: {speedup:.2f}x\")\n",
    "elif 'numba_avg_time' not in locals():\n",
    "     print(\"Cannot calculate speedup because Numba benchmark failed.\")\n",
    "else:\n",
    "     print(\"Cannot calculate speedup because NumPy benchmark failed.\")"
   ],
   "id": "ff945fed4ad5c05b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmarking on a cell grid of size: (500 x 500)\n",
      "Input vector shape: (500, 500, 2)\n",
      "------------------------------\n",
      "Running correctness check...\n",
      "Correctness check PASSED: NumPy and Numba results are close.\n",
      "Output shape: (499, 499)\n",
      "------------------------------\n",
      "NumPy Standalone Version:\n",
      "  Average time: 0.001641 seconds\n",
      "  Std dev:      0.000348 seconds\n",
      "Numba 2D Kernel Version:\n",
      "  Average time: 0.000728 seconds\n",
      "  Std dev:      0.000110 seconds\n",
      "------------------------------\n",
      "Numba speedup over NumPy: 2.26x\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1b6b4eda5d05d3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
